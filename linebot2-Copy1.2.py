import os
import shutil
import subprocess
import threading
import torch
import io
import json
import logging
import traceback
import re
import subprocess

from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage, ImageMessage, ImageSendMessage,
    TemplateSendMessage, ButtonsTemplate, PostbackAction, PostbackEvent, FlexSendMessage,
    BubbleContainer, BoxComponent, TextComponent, ButtonComponent
)

from webuiapi import WebUIApi
from deep_translator import GoogleTranslator

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload # Import MediaIoBaseDownload for efficient downloading

app = Flask(__name__)

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === LINE Bot è¨­å®š ===
LINE_CHANNEL_ACCESS_TOKEN = 'lEjwrG6VNT4HFBelZy8rwFKKV9dOZrn1On5+ZO1TlF4XBS27ixlEJoDISs/lsTK7ttsZ4J/VDr9GyO8yEzufkKnTmMQ+WN5ILcY2C82hPnOxRYn5D5cfV/EJzWpJ8k87CpMniI2Kbq6HLPQvFhkZbgdB04t89/1O/w1cDnyilFU='
LINE_CHANNEL_SECRET = '391269aaead5a69836c02fba3fedf3d2'

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# === è³‡æ–™å¤¾èˆ‡è…³æœ¬è·¯å¾‘è¨­å®š ===
UPLOAD_FOLDER = '/home/user/lora-train/lora-scripts/linebot_images/20_chien'
TAGGER_PYTHON = '/home/user/lora-train/tagger/venv/bin/python3'
TAGGING_SCRIPT = '/home/user/lora-train/tagger/phi3_fast.py'
TRAIN_SCRIPT = '/home/user/lora-train/lora-scripts/train-t1-Copy1.sh'
TRAIN_SCRIPT_DIR = '/home/user/lora-train/lora-scripts'

# ä½ çš„ç”Ÿåœ–è…³æœ¬è·¯å¾‘å’Œè¼¸å‡ºè³‡æ–™å¤¾
GENERATE_SCRIPT = '/home/user/lora-train/lora-scripts/stable-diffusion-webui/chien-generate_random_seeds.py'
GENERATED_IMAGES_OUTPUT_FOLDER = "/home/user/lora-train/lora-scripts/random_output" # ç¢ºä¿ä½ çš„è…³æœ¬æœƒå°‡åœ–ç‰‡è¼¸å‡ºåˆ°é€™è£¡

# === ç”Ÿåœ–è…³æœ¬è¨­å®š ===
# If you have a separate Python script for generation with custom seeds, use it.
# Otherwise, we'll use webuiapi's txt2img directly.
# GENERATE_SCRIPT = '/home/user/lora-train/lora-scripts/stable-diffusion-webui/chien-generate_random_seeds.py'

# === çµ±ä¸€çš„è¼¸å‡ºè³‡æ–™å¤¾ï¼Œç”¨æ–¼æ‰€æœ‰ç”Ÿæˆçš„åœ–ç‰‡ ===
CONSOLIDATED_OUTPUT_FOLDER = "/home/user/lora-train/lora-scripts/generated_images_output"
# è¨“ç·´å¥½çš„ LoRA æ¨¡å‹æœƒæš«æ™‚æ”¾åœ¨é€™è£¡ï¼Œç›´åˆ°ä¸Šå‚³åˆ° Google Drive
LORA_OUTPUT_FOLDER = "/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Lora"


# === Stable Diffusion API è¨­å®š ===
SD_API = WebUIApi(host="127.0.0.1", port=7860)
MODEL_FOLDER = "/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Stable-diffusion"
SD_LORA_DOWNLOAD_FOLDER = "/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Lora"

# === Google Drive è¨­å®š ===
GOOGLE_DRIVE_OUTPUT_FOLDER_ID = "1_9QLHupRK8e-CjfLh70mNdesVIuveZ1"
GOOGLE_DRIVE_LORA_MODELS_FOLDER_ID = "1CXA9TXfEWXHbm0og7Zws1jqkFq2F67B"

SCOPES = ["https://www.googleapis.com/auth/drive"]
SERVICE_ACCOUNT_FILE = "/home/user/lora-train/elite-mix-441517-k7-618329de7f11.json"

# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(CONSOLIDATED_OUTPUT_FOLDER, exist_ok=True)
os.makedirs(SD_LORA_DOWNLOAD_FOLDER, exist_ok=True)

# å…¨åŸŸç‹€æ…‹è®Šæ•¸
uploading = False # å…¨å±€å˜é‡

def my_function():
    global uploading # é¦–å…ˆå£°æ˜ä¸ºå…¨å±€å˜é‡
    print(uploading) # ç°åœ¨ Python çŸ¥é“å®ƒæ˜¯å…¨å±€å˜é‡äº†
    uploading = True
user_id_for_process = None

# ç”¨æˆ¶ç‹€æ…‹ç®¡ç†
user_states = {}

# === Google Drive èªè­‰åˆå§‹åŒ–å‡½æ•¸ ===
def authenticate_google_drive():
    try:
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES
        )
        service = build('drive', 'v3', credentials=creds)
        logging.info("Google Drive èªè­‰æˆåŠŸï¼")
        return service
    except Exception as e:
        logging.error(f"Google Drive èªè­‰å¤±æ•—: {e}")
        return None

# åˆå§‹åŒ– Google Drive æœå‹™
drive_service = authenticate_google_drive()
if not drive_service:
    logging.critical("ğŸš¨ Google Drive æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œç¨‹å¼å°‡ç„¡æ³•ä¸Šå‚³æª”æ¡ˆã€‚è«‹æª¢æŸ¥æœå‹™å¸³æˆ¶é‡‘é‘°ã€‚")

# --- ä¸Šå‚³åœ–ç‰‡åˆ° Google Drive ä¸¦ç²å–å…¬é–‹é€£çµå‡½æ•¸ ---
def upload_to_drive_and_get_public_link(drive_service_instance, file_path, folder_id):
    """
    ä¸Šå‚³å–®ä¸€æª”æ¡ˆåˆ° Google Driveï¼Œä¸¦è¨­å®šå…¬é–‹æ¬Šé™ï¼Œå›å‚³å…¬é–‹é€£çµ(URL)ã€‚
    é©ç”¨æ–¼ä»»ä½•æ–‡ä»¶é¡å‹ï¼ŒåŒ…æ‹¬åœ–ç‰‡å’Œ LoRA æ¨¡å‹ã€‚
    """
    try:
        file_metadata = {
            'name': os.path.basename(file_path),
            'parents': [folder_id]
        }
        media = MediaFileUpload(file_path, resumable=True)
        file = drive_service_instance.files().create(body=file_metadata, media_body=media, fields='id, webContentLink, webViewLink').execute()

        # è¨­å®šå…¬é–‹æ¬Šé™
        drive_service_instance.permissions().create(
            fileId=file['id'],
            body={'type': 'anyone', 'role': 'reader'},
        ).execute()

        # For files like images that can be viewed directly in the browser, prefer webViewLink
        # For downloadable files, webContentLink usually provides a direct download or preview
        # If webContentLink is not suitable for direct image display in LINE, we might need a custom approach or force download link
        if 'webViewLink' in file:
            public_link = file['webViewLink']
        elif 'webContentLink' in file:
            public_link = file['webContentLink']
        else:
            # Fallback for direct download link
            public_link = f"https://drive.google.com/uc?id={file['id']}&export=download"
        
        logging.info(f"Uploaded {os.path.basename(file_path)} to Google Drive. Public link: {public_link}")
        return public_link
    except Exception as e:
        logging.error(f"ä¸Šå‚³ Google Drive å¤±æ•—: {e}")
        traceback.print_exc()
        return None

# --- å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆåˆ°æœ¬åœ° ---
def download_file_from_drive(drive_service_instance, file_id, destination_path):
    """
    å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆã€‚
    """
    try:
        request = drive_service_instance.files().get_media(fileId=file_id)
        fh = io.FileIO(destination_path, 'wb')
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
            # print(f"Download progress: {int(status.progress() * 100)}%")
        logging.info(f"Downloaded file {file_id} to {destination_path}")
        return True
    except HttpError as e:
        logging.error(f"å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆ {file_id} æ™‚ç™¼ç”Ÿ HTTP éŒ¯èª¤: {e}", exc_info=True)
        return False
    except Exception as e:
        logging.error(f"å¾ Google Drive ä¸‹è¼‰æª”æ¡ˆ {file_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
        return False


# === å·¥å…·å‡½å¼ ===
def list_models():
    """åˆ—å‡º Stable Diffusion æ¨¡å‹è³‡æ–™å¤¾ä¸­çš„æ¨¡å‹åç¨±"""
    try:
        models = [f for f in os.listdir(MODEL_FOLDER) if f.endswith(".safetensors")]
        models = [m for m in models if "Put Stable Diffusion checkpoints here.txt" not in m]
        return models
    except Exception as e:
        logging.error(f"ç„¡æ³•åˆ—å‡º Stable Diffusion æ¨¡å‹: {e}")
        return []

# --- å¾ Google Drive åˆ—å‡º LoRA æ¨¡å‹ ---
def list_lora_models_from_drive(drive_service_instance, folder_id):
    """
    å¾ Google Drive çš„æŒ‡å®šè³‡æ–™å¤¾ä¸­åˆ—å‡ºæ‰€æœ‰ LoRA æ¨¡å‹ã€‚
    è¿”å›ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ ç‚º {'name': æª”æ¡ˆåç¨± (ä¸å«å‰¯æª”å), 'file_id': æª”æ¡ˆID, 'original_name': æª”æ¡ˆåç¨± (ä¸å«å‰¯æª”å)}
    """
    lora_models = []
    try:
        query = f"'{folder_id}' in parents and mimeType!='application/vnd.google-apps.folder' and trashed=false"
        results = drive_service_instance.files().list(
            q=query,
            pageSize=100,
            fields="nextPageToken, files(id, name)"
        ).execute()
        items = results.get('files', [])

        for item in items:
            file_name = item['name']
            if file_name.endswith('.safetensors') or file_name.endswith('.pt'):
                lora_tag = file_name.replace('.safetensors', '').replace('.pt', '')
                lora_models.append({
                    'name': lora_tag,
                    'file_id': item['id'],
                    'original_name': lora_tag
                })
        logging.info(f"å¾ Google Drive åˆ—å‡º {len(lora_models)} å€‹ LoRA æ¨¡å‹ã€‚")
    except HttpError as e:
        logging.error(f"å¾ Google Drive åˆ—å‡º LoRA æ¨¡å‹æ™‚ç™¼ç”Ÿ HTTP éŒ¯èª¤: {e}", exc_info=True)
    except Exception as e:
        logging.error(f"å¾ Google Drive åˆ—å‡º LoRA æ¨¡å‹æ™‚ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤: {e}", exc_info=True)
    return lora_models


def send_main_menu(user_id):
    """å‚³é€ä¸»åŠŸèƒ½é¸å–®çµ¦ä½¿ç”¨è€… (Flex Message ç‰ˆæœ¬)"""
    flex_message = BubbleContainer(
        size="mega",
        body=BoxComponent(
            layout="vertical",
            spacing="md",
            contents=[
                TextComponent(
                    text="è«‹é¸æ“‡åŠŸèƒ½",
                    weight="bold",
                    size="xl",
                    align="center"
                ),
                ButtonComponent(
                    style="primary",
                    color="#FAB1A0",
                    action={"type": "message", "label": "ç”Ÿåœ–åŠŸèƒ½", "text": "ç”Ÿåœ–åŠŸèƒ½"}
                ),
                ButtonComponent(
                    style="primary",
                    color="#4A90E2",
                    action={"type": "message", "label": "åœ–ç‰‡è¨“ç·´åŠŸèƒ½", "text": "åœ–ç‰‡è¨“ç·´åŠŸèƒ½"}
                ),
                ButtonComponent(
                    style="primary",
                    color="#6C5CE7",
                    action={"type": "postback", "label": "æˆ‘çš„ LoRA æ¨¡å‹", "data": "action=my_models"}
                )
            ]
        )
    )
    line_bot_api.push_message(user_id, FlexSendMessage(alt_text="è«‹é¸æ“‡åŠŸèƒ½", contents=flex_message))
    logging.info(f"User {user_id} received main menu.")

# === Webhook æ¥æ”¶ ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers["X-Line-Signature"]
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logging.error("Invalid signature. Please check your channel access token/channel secret.")
        abort(400)
    except Exception as e:
        logging.error(f"Line Bot Error: {e}")
        abort(400)
    return "OK"

# === è™•ç†æ–‡å­—è¨Šæ¯ ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    global uploading, user_id_for_process
    user_id = event.source.user_id
    message_text = event.message.text.strip()

    if user_id not in user_states:
        user_states[user_id] = {
            'mode': 'main_menu',
            'image_count': 0,
            'prompt': None,
            'lang': 'zh',
            'selected_lora_info': None,
            'latest_trained_lora_path': None # Store the path to the newly trained LoRA
        }
    current_state = user_states[user_id]
    current_mode = current_state['mode']
    current_lang = current_state['lang']

    logging.info(f"User {user_id} in mode '{current_mode}' sent text: '{message_text}'")

    if message_text == "menu" or message_text == "é¸å–®":
        send_main_menu(user_id)
        current_state['mode'] = 'main_menu'
        current_state['prompt'] = None
        current_state['selected_lora_info'] = None
        current_state['latest_trained_lora_path'] = None # Clear any pending trained LoRA
        current_state['image_count'] = 0
        uploading = False
        return

    if message_text.lower() in ["ä¸­æ–‡", "chinese"]:
        current_state['lang'] = "zh"
        line_bot_api.reply_message(event.reply_token, TextSendMessage("èªè¨€å·²åˆ‡æ›ç‚ºä¸­æ–‡ï¼"))
        return
    elif message_text.lower() in ["è‹±æ–‡", "english"]:
        current_state['lang'] = "en"
        line_bot_api.reply_message(event.reply_token, TextSendMessage("Language switched to English!"))
        return

    if message_text == "åœ–ç‰‡è¨“ç·´åŠŸèƒ½":
        if not uploading:
            if os.path.exists(UPLOAD_FOLDER):
                shutil.rmtree(UPLOAD_FOLDER)
                logging.info(f"Cleared old UPLOAD_FOLDER contents for user {user_id} before new training.")
            os.makedirs(UPLOAD_FOLDER)

            current_state['mode'] = 'image_training'
            current_state['image_count'] = 0
            uploading = True
            user_id_for_process = user_id
            reply_text = "è«‹é–‹å§‹å‚³é€åœ–ç‰‡ï¼ï¼ˆå…± 20 å¼µï¼‰" if current_lang == "zh" else "Please start sending images! (20 images in total)"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            logging.info(f"User {user_id} entered image training mode.")
        else:
            reply_text = "ç›®å‰å·²æœ‰åœ–ç‰‡è¨“ç·´æµç¨‹æ­£åœ¨é€²è¡Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚" if current_lang == "zh" else "An image training process is currently in progress, please try again later."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    if message_text == "ç”Ÿåœ–åŠŸèƒ½":
        current_state['mode'] = 'image_generation'
        current_state['prompt'] = None
        current_state['selected_lora_info'] = None
        current_state['latest_trained_lora_path'] = None # Clear any pending trained LoRA
        reply_text = "è«‹è¼¸å…¥æ‚¨çš„æç¤ºè© (Positive Prompt)ï¼" if current_lang == "zh" else "Please enter your prompt (Positive Prompt)!"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} entered image generation mode.")
        return

    # Handle text messages in specific states
    if current_mode == 'image_training':
        reply_text = f"æ‚¨ç›®å‰åœ¨åœ–ç‰‡è¨“ç·´æ¨¡å¼ã€‚è«‹ç¹¼çºŒä¸Šå‚³åœ–ç‰‡ï¼Œç›®å‰å·²ä¸Šå‚³ {current_state['image_count']} å¼µã€‚" if current_lang == "zh" else f"You are in image training mode. Please continue uploading images. Current: {current_state['image_count']} images."
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    if current_mode == 'image_generation':
        if current_state['prompt'] is None:
            current_state['prompt'] = message_text
            # If there's a recently trained LoRA and the user hasn't selected one yet, offer it first
            if current_state['latest_trained_lora_path'] and not current_state['selected_lora_info']:
                lora_filename = os.path.basename(current_state['latest_trained_lora_path'])
                lora_tag = lora_filename.replace('.safetensors', '').replace('.pt', '')
                confirm_message = TextSendMessage(
                    text=f"åµæ¸¬åˆ°æ‚¨å‰›è¨“ç·´å®Œæˆ LoRA æ¨¡å‹ï¼š**{lora_tag}**ã€‚\næ‚¨æƒ³ç”¨é€™å€‹æ¨¡å‹ä¾†ç”Ÿåœ–é è¦½å—ï¼Ÿ" if current_lang == "zh" else
                         f"Detected your newly trained LoRA model: **{lora_tag}**.\nWould you like to use this model for image preview?"
                )
                confirm_buttons = TemplateSendMessage(
                    alt_text="ä½¿ç”¨æ–°æ¨¡å‹é è¦½ï¼Ÿ",
                    template=ButtonsTemplate(
                        title="ä½¿ç”¨æ–°æ¨¡å‹ï¼Ÿ" if current_lang == "zh" else "Use New Model?",
                        text=lora_tag,
                        actions=[
                            PostbackAction(
                                label="æ˜¯ï¼Œç”¨å®ƒé è¦½" if current_lang == "zh" else "Yes, preview with it",
                                data=f"action=use_new_lora_preview&lora_path={current_state['latest_trained_lora_path']}"
                            ),
                            PostbackAction(
                                label="å¦ï¼Œé¸æ“‡å…¶ä»–" if current_lang == "zh" else "No, select another",
                                data="action=select_base_model" # Go to base model selection
                            )
                        ]
                    )
                )
                line_bot_api.reply_message(event.reply_token, [confirm_message, confirm_buttons])
            else:
                # Proceed to base model selection if no new LoRA or already selected
                send_base_model_selection(user_id, event.reply_token, current_lang)
            return
        else:
            reply_text = "è«‹å…ˆé¸æ“‡æ¨¡å‹ã€‚" if current_lang == "zh" else "Please choose a model first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    reply_text = "è«‹è¼¸å…¥ 'menu' æŸ¥çœ‹åŠŸèƒ½é¸å–®ã€‚" if current_lang == "zh" else "Please type 'menu' to see the function menu."
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

def send_base_model_selection(user_id, reply_token, current_lang):
    model_list = list_models()
    display_models = model_list[:4] if model_list else ["No models found.safetensors"]
    actions = [PostbackAction(label=model[:20], data=f"model={model}") for model in display_models]
    template = ButtonsTemplate(
        title="é¸æ“‡åŸºç¤æ¨¡å‹" if current_lang == "zh" else "Choose Base Model",
        text="è«‹é¸æ“‡æ¨¡å‹ä¾†ç”Ÿæˆåœ–ç‰‡" if current_lang == "zh" else "Select model to generate image",
        actions=actions
    )
    line_bot_api.reply_message(reply_token, TemplateSendMessage(alt_text="Select model", template=template))
    logging.info(f"User {user_id} awaiting base model selection.")

# === è™•ç†åœ–ç‰‡è¨Šæ¯ ===
@handler.add(MessageEvent, message=ImageMessage)
def handle_image(event):
    global uploading, user_id_for_process
    user_id = event.source.user_id

    if user_id not in user_states or user_states[user_id]['mode'] != 'image_training' or not uploading:
        logging.info(f"Received image from {user_id} but not in image training mode or uploading state. Ignoring.")
        return

    current_state = user_states[user_id]
    current_lang = current_state['lang']

    current_count = len([f for f in os.listdir(UPLOAD_FOLDER) if f.lower().endswith(('.jpg', '.png', '.jpeg'))])

    if current_count >= 20:
        logging.info(f"User {user_id} tried to upload more than 20 images. Current: {current_count}. Ignoring.")
        return

    new_index = current_count + 1
    filename = f"{new_index:02d}.png"
    image_path = os.path.join(UPLOAD_FOLDER, filename)

    try:
        image_content = line_bot_api.get_message_content(event.message.id)
        with open(image_path, 'wb') as f:
            for chunk in image_content.iter_content():
                f.write(chunk)

        logging.info(f"User {user_id} saved image {filename}. Total: {new_index}")
        current_state['image_count'] = new_index

        if new_index == 20:
            logging.info(f"User {user_id} received 20 images, preparing to start tagging, training, and generation.")
            uploading = False
            current_state['mode'] = 'main_menu' # Reset mode after image upload completion

            threading.Thread(target=run_full_pipeline, args=(user_id,)).start()
            reply_text = "å·²æ”¶åˆ°æ‰€æœ‰ 20 å¼µåœ–ç‰‡ã€‚é–‹å§‹æ¨™è¨»èˆ‡è¨“ç·´ï¼Œé€™éœ€è¦ä¸€äº›æ™‚é–“ï¼Œå®Œæˆå¾Œæœƒé€šçŸ¥æ‚¨ã€‚" if current_lang == "zh" else "All 20 images received. Starting tagging and training, this will take some time. You will be notified when complete."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

    except Exception as e:
        logging.error(f"Error saving image for user {user_id}: {e}", exc_info=True)
        reply_text = f"åœ–ç‰‡å„²å­˜å¤±æ•—ï¼š{str(e)}" if current_lang == "zh" else f"Failed to save image: {str(e)}"
        line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

# === è™•ç†æ¨¡å‹æŒ‰éˆ•é¸æ“‡ ===
@handler.add(PostbackEvent)
def handle_postback(event):
    user_id = event.source.user_id
    data = event.postback.data
    logging.info(f"User {user_id} postback data: {data}")

    if user_id not in user_states:
        user_states[user_id] = {
            'mode': 'main_menu',
            'lang': 'zh',
            'prompt': None,
            'selected_lora_info': None,
            'latest_trained_lora_path': None
        }
    current_state = user_states[user_id]
    current_lang = current_state['lang']

    # --- è™•ç†åŸºç¤æ¨¡å‹é¸æ“‡ ---
    if data.startswith("model="):
        model_name = data.split("=", 1)[1]
        prompt = current_state.get('prompt')

        if not prompt:
            reply_text = "è«‹å…ˆè¼¸å…¥æç¤ºè©ã€‚" if current_lang == "zh" else "Please enter prompt first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return

        line_bot_api.reply_message(event.reply_token, TextSendMessage(
            "æ­£åœ¨ç”Ÿæˆåœ–ç‰‡ä¸­ï¼Œè«‹ç¨å€™..." if current_lang == "zh" else "Generating image, please wait..."
        ))
        logging.info(f"User {user_id} selected base model: {model_name}, prompt: '{prompt}'")

        threading.Thread(target=run_sd_generation, args=(user_id, prompt, model_name, current_state.get('selected_lora_info'), event.reply_token)).start()
        
        # Clear states after starting generation
        current_state['prompt'] = None
        current_state['selected_lora_info'] = None
        current_state['latest_trained_lora_path'] = None # Ensure this is cleared
        current_state['mode'] = 'main_menu'
        return

    # --- è™•ç†ã€Œæˆ‘çš„ LoRA æ¨¡å‹ã€Postback äº‹ä»¶ï¼šå¾ Google Drive åˆ—å‡º LoRA æ¨¡å‹ ---
    elif data == "action=my_models":
        lora_models_from_drive = list_lora_models_from_drive(drive_service, GOOGLE_DRIVE_LORA_MODELS_FOLDER_ID)
        
        if not lora_models_from_drive:
            reply_text = "Google Drive ä¸Šç›®å‰æ²’æœ‰æ‰¾åˆ° LoRA æ¨¡å‹å–”ï¼" if current_lang == "zh" else "No LoRA models found on Google Drive yet!"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return

        buttons_contents = []
        for model_info in lora_models_from_drive:
            buttons_contents.append(
                ButtonComponent(
                    style="link",
                    height="sm",
                    action=PostbackAction(
                        label=model_info['name'][:20],
                        data=f"action=select_lora&lora_name={model_info['name']}&lora_file_id={model_info['file_id']}&original_name={model_info['original_name']}"
                    )
                )
            )
            if len(buttons_contents) >= 10:
                break
        
        if not buttons_contents:
            line_bot_api.reply_message(event.reply_token, TextSendMessage("æ²’æœ‰å¯ç”¨çš„ LoRA æ¨¡å‹ã€‚" if current_lang == "zh" else "No LoRA models available."))
            return

        flex_message = BubbleContainer(
            size="giga",
            body=BoxComponent(
                layout="vertical",
                spacing="md",
                contents=[
                    TextComponent(
                        text="è«‹é¸æ“‡æ‚¨è¦ä½¿ç”¨çš„ LoRA æ¨¡å‹" if current_lang == "zh" else "Please select the LoRA model you want to use",
                        weight="bold",
                        size="xl",
                        align="center"
                    )
                ] + buttons_contents
            )
        )
        line_bot_api.reply_message(event.reply_token, FlexSendMessage(alt_text="é¸æ“‡æˆ‘çš„æ¨¡å‹", contents=flex_message))
        logging.info(f"User {user_id} requested my models list from Google Drive.")
        return

    # --- è™•ç† LoRA æ¨¡å‹é¸æ“‡ Postback äº‹ä»¶ (å¾ Drive æˆ–æœ¬åœ°) ---
    elif data.startswith("action=select_lora"):
        parts = data.split('&')
        selected_lora_name = None
        selected_lora_file_id = None
        original_lora_name = None

        for part in parts:
            if part.startswith("lora_name="):
                selected_lora_name = part.split("=", 1)[1]
            elif part.startswith("lora_file_id="):
                selected_lora_file_id = part.split("=", 1)[1]
            elif part.startswith("original_name="):
                original_lora_name = part.split("=", 1)[1]

        if not selected_lora_name or not selected_lora_file_id or not original_lora_name:
            line_bot_api.reply_message(event.reply_token, TextSendMessage("éŒ¯èª¤ï¼šç„¡æ³•ç²å–æ¨¡å‹è³‡è¨Šã€‚è«‹é‡æ–°å˜—è©¦ã€‚" if current_lang == "zh" else "Error: Could not retrieve model information. Please try again."))
            return

        current_state['selected_lora_info'] = {
            'name': selected_lora_name,
            'file_id': selected_lora_file_id,
            'original_name': original_lora_name,
            'is_local': False # Mark as not local, will be downloaded if needed
        }
        current_state['mode'] = 'image_generation'
        current_state['latest_trained_lora_path'] = None # Clear this as user selected from Drive

        reply_text = f"æ‚¨å·²é¸æ“‡ LoRA æ¨¡å‹ï¼š**{selected_lora_name}**ã€‚\nç¾åœ¨è«‹è¼¸å…¥æ‚¨çš„æç¤ºè© (Positive Prompt)ï¼" if current_lang == "zh" else \
                     f"You have selected LoRA model: **{selected_lora_name}**.\nNow please enter your prompt (Positive Prompt)!"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} selected LoRA from Drive: {selected_lora_name} ({selected_lora_file_id}). Ready for generation.")
        return

    # --- è™•ç†ä½¿ç”¨æ–°è¨“ç·´çš„ LoRA é è¦½çš„ Postback äº‹ä»¶ ---
    elif data.startswith("action=use_new_lora_preview"):
        lora_path = data.split("lora_path=", 1)[1]
        lora_filename = os.path.basename(lora_path)
        lora_tag = lora_filename.replace('.safetensors', '').replace('.pt', '')

        if not os.path.exists(lora_path):
            line_bot_api.reply_message(event.reply_token, TextSendMessage("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ–°çš„ LoRA æ¨¡å‹æª”æ¡ˆã€‚è«‹é‡æ–°è¨“ç·´æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹ã€‚" if current_lang == "zh" else "Error: New LoRA model file not found. Please retrain or select another model."))
            return

        # Set the selected_lora_info to the locally trained model
        current_state['selected_lora_info'] = {
            'name': lora_tag,
            'file_id': None, # No file ID for local file
            'original_name': lora_tag,
            'is_local': True, # Mark as local
            'local_path': lora_path # Store local path for direct use
        }
        current_state['latest_trained_lora_path'] = None # Consume the pending LoRA
        current_state['mode'] = 'image_generation' # Ensure mode is correct

        prompt = current_state.get('prompt')
        if not prompt:
            reply_text = "è«‹å…ˆè¼¸å…¥æç¤ºè©ã€‚" if current_lang == "zh" else "Please enter prompt first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return

        line_bot_api.reply_message(event.reply_token, TextSendMessage(
            f"æ­£åœ¨ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ **{lora_tag}** ç”Ÿæˆé è¦½åœ–ï¼Œè«‹ç¨å€™..." if current_lang == "zh" else f"Generating preview image with your new model **{lora_tag}**, please wait..."
        ))
        logging.info(f"User {user_id} chose to preview with new LoRA: {lora_tag}.")

        # Generate preview images using the *newly trained* LoRA
        threading.Thread(target=generate_preview_and_ask_upload, args=(user_id, prompt, "ChilloutMix-Ni-pruned-fp32.safetensors", current_state['selected_lora_info'])).start()
        return

    # --- è™•ç†ä¸ä½¿ç”¨æ–°è¨“ç·´çš„ LoRAï¼Œé¸æ“‡åŸºç¤æ¨¡å‹ (å¾ "å¦ï¼Œé¸æ“‡å…¶ä»–" æŒ‰éˆ•) ---
    elif data == "action=select_base_model":
        current_state['latest_trained_lora_path'] = None # Clear the pending new LoRA
        send_base_model_selection(user_id, event.reply_token, current_lang)
        return

    # --- è™•ç†é è¦½åœ–å¾Œçš„ä¸Šå‚³ç¢ºèª ---
    elif data.startswith("action=upload_lora"):
        lora_path_to_upload = data.split("lora_path=", 1)[1]
        if not os.path.exists(lora_path_to_upload):
            line_bot_api.reply_message(event.reply_token, TextSendMessage("éŒ¯èª¤ï¼šæ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œç„¡æ³•ä¸Šå‚³ã€‚" if current_lang == "zh" else "Error: Model file not found, cannot upload."))
            return

        line_bot_api.reply_message(event.reply_token, TextSendMessage("å¥½çš„ï¼Œæ­£åœ¨å°‡æ‚¨çš„ LoRA æ¨¡å‹ä¸Šå‚³åˆ° Google Drive..." if current_lang == "zh" else "Okay, uploading your LoRA model to Google Drive..."))
        threading.Thread(target=upload_lora_to_drive_thread, args=(user_id, lora_path_to_upload)).start()
        # Reset relevant state after initiating upload
        current_state['latest_trained_lora_path'] = None
        current_state['mode'] = 'main_menu'
        return

    # --- è™•ç†é è¦½åœ–å¾Œä¸æ»¿æ„ï¼Œä¸é€²è¡Œä¸Šå‚³ ---
    elif data == "action=skip_upload_lora":
        line_bot_api.reply_message(event.reply_token, TextSendMessage("å¥½çš„ï¼ŒLoRA æ¨¡å‹å°‡ä¸æœƒä¸Šå‚³åˆ° Google Driveã€‚æ‚¨å¯ä»¥éš¨æ™‚é‡æ–°è¨“ç·´æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹ã€‚" if current_lang == "zh" else "Okay, the LoRA model will not be uploaded to Google Drive. You can retrain or select other models at any time."))
        # Clear the locally trained LoRA path and reset mode
        current_state['latest_trained_lora_path'] = None
        # Optionally, remove the local LoRA file if it's no longer needed
        # if current_state['selected_lora_info'] and current_state['selected_lora_info']['is_local']:
        #     if os.path.exists(current_state['selected_lora_info']['local_path']):
        #         os.remove(current_state['selected_lora_info']['local_path'])
        #         logging.info(f"Deleted local LoRA file: {current_state['selected_lora_info']['local_path']}")
        current_state['selected_lora_info'] = None
        current_state['mode'] = 'main_menu'
        send_main_menu(user_id) # Send main menu for next action
        return

    logging.warning(f"Unhandled postback event from user {user_id}: {data}")

# --- åŸ·è¡Œå®Œæ•´çš„è¨“ç·´èˆ‡ç”Ÿåœ–æµç¨‹ ---
def run_full_pipeline(user_id):
    global uploading
    drive_service_pipeline = authenticate_google_drive()
    if not drive_service_pipeline:
        line_bot_api.push_message(user_id, TextSendMessage(text="âŒ ç„¡æ³•é€£æ¥åˆ° Google Drive æœå‹™ï¼Œè«‹æª¢æŸ¥æœå‹™å¸³æˆ¶é‡‘é‘°ã€‚"))
        user_states[user_id]['mode'] = 'main_menu'
        user_states[user_id]['image_count'] = 0
        global uploading
        uploading = False
        return

    current_lang = user_states.get(user_id, {}).get('lang', 'zh')
    current_state = user_states[user_id] # Get current state to store latest_trained_lora_path

    try:
        line_bot_api.push_message(user_id, TextSendMessage(text="åœ–ç‰‡ä¸Šå‚³å®Œæˆï¼Œé–‹å§‹æ¨™è¨»å•¦!" if current_lang == "zh" else "Image upload complete, starting tagging!"))
        logging.info(f"User {user_id} started tagging process.")

        # === Step 1: åŸ·è¡Œæ¨™è¨»è…³æœ¬ ===
        print("ğŸš€ é–‹å§‹åŸ·è¡Œæ¨™è¨»è…³æœ¬...")
        tag_result = subprocess.run(
            [
                TAGGER_PYTHON,
                TAGGING_SCRIPT,
                UPLOAD_FOLDER,
                "--character_name", "chien",
                "--trigger_word", "masterpiece"
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=TRAIN_SCRIPT_DIR
        )
        logging.info(f"Tagger stdout for user {user_id}:\n{tag_result.stdout}")
        logging.error(f"Tagger stderr for user {user_id}:\n{tag_result.stderr}")
        line_bot_api.push_message(user_id, TextSendMessage(text="æ¨™è¨»å®Œæˆï¼ŒåŸ·è¡Œæ¨¡å‹è¨“ç·´ï¼Œéœ€è¦å¤§æ¦‚10-15åˆ†é˜ã€‚" if current_lang == "zh" else "Tagging complete, starting model training, this will take about 10-15 minutes."))

        # === Step 2: æ¨™è¨»æˆåŠŸå¾ŒåŸ·è¡Œè¨“ç·´ ===
        print("ğŸš€ é–‹å§‹åŸ·è¡Œæ¨¡å‹è¨“ç·´è…³æœ¬...")
        train_result = subprocess.run(
            ['bash', TRAIN_SCRIPT],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=TRAIN_SCRIPT_DIR,
            timeout=3000
        )
        logging.info(f"Train stdout for user {user_id}:\n{train_result.stdout}")
        logging.error(f"Train stderr for user {user_id}:\n{train_result.stderr}")
        line_bot_api.push_message(user_id, TextSendMessage(text="æ¨¡å‹è¨“ç·´å·²æˆåŠŸå®Œæˆï¼ğŸ‰ é–‹å§‹æº–å‚™ç”Ÿæˆé è¦½åœ–..." if current_lang == "zh" else "Model training completed successfully! ğŸ‰ Preparing to generate preview images..."))

        # === Step 3: è¨“ç·´æˆåŠŸå¾Œï¼Œæ‰¾åˆ°è¨“ç·´å¥½çš„ LoRA æ¨¡å‹æª”æ¡ˆ ===
        lora_files = [f for f in os.listdir(LORA_OUTPUT_FOLDER) if f.endswith('.safetensors') or f.endswith('.pt')]
        lora_files.sort(key=lambda x: os.path.getmtime(os.path.join(LORA_OUTPUT_FOLDER, x)), reverse=True)

        if lora_files:
            latest_lora_file = lora_files[0]
            latest_lora_path = os.path.join(LORA_OUTPUT_FOLDER, latest_lora_file)
            current_state['latest_trained_lora_path'] = latest_lora_path # Store the path

            # Prompt user to enter a prompt for preview generation
            reply_text = f"æ­å–œï¼æ‚¨çš„å°ˆå±¬ LoRA æ¨¡å‹ **{latest_lora_file.replace('.safetensors', '').replace('.pt', '')}** å·²è¨“ç·´å®Œæˆï¼\n\nç¾åœ¨è«‹è¼¸å…¥ä¸€å€‹æç¤ºè©ï¼Œæˆ‘å€‘å°‡ç‚ºæ‚¨ç”Ÿæˆå¹¾å¼µé è¦½åœ–ï¼Œè®“æ‚¨è©•ä¼°æ¨¡å‹æ•ˆæœã€‚\nï¼ˆå¦‚æœæ‚¨å°æ¨¡å‹ä¸æ»¿æ„ï¼Œå¯ä»¥é¸æ“‡ä¸å°‡å®ƒä¸Šå‚³åˆ° Google Driveã€‚ï¼‰" if current_lang == "zh" else \
                         f"Congratulations! Your exclusive LoRA model **{latest_lora_file.replace('.safetensors', '').replace('.pt', '')}** has been trained!\n\nPlease enter a prompt now. We will generate some preview images for you to evaluate the model's quality.\n(If you are not satisfied with the model, you can choose not to upload it to Google Drive.)"
            line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))
            current_state['mode'] = 'image_generation' # Switch to image generation mode to receive prompt
            current_state['prompt'] = None # Clear prompt for new input

        else:
            line_bot_api.push_message(user_id, TextSendMessage("âŒ æœªæ‰¾åˆ°è¨“ç·´å®Œæˆçš„ LoRA æ¨¡å‹æª”æ¡ˆã€‚è«‹æª¢æŸ¥è¨“ç·´è…³æœ¬çš„è¼¸å‡ºè·¯å¾‘ã€‚" if current_lang == "zh" else "âŒ No trained LoRA model file found. Please check the training script's output path."))
            logging.error(f"No trained LoRA model file found in {LORA_OUTPUT_FOLDER} after training.")
            send_main_menu(user_id) # Go back to main menu
            current_state['mode'] = 'main_menu'


    except subprocess.CalledProcessError as e:
        error_message = f"è…³æœ¬åŸ·è¡Œå¤±æ•—ã€‚éŒ¯èª¤è¨Šæ¯ï¼š{e.stderr}" if current_lang == "zh" else f"Script execution failed. Error: {e.stderr}"
        logging.error(f"Script execution failed for user {user_id}: {error_message}")
        line_bot_api.push_message(user_id, TextSendMessage(text=f"åœ–ç‰‡æ¨™è¨»æˆ–è¨“ç·´å¤±æ•—ï¼š{error_message}"))

    except FileNotFoundError as e:
        error_message = f"æ‰¾ä¸åˆ°å¿…è¦çš„æª”æ¡ˆï¼š{e.filename}" if current_lang == "zh" else f"Required file not found: {e.filename}"
        logging.error(f"File not found for user {user_id}: {error_message}")
        line_bot_api.push_message(user_id, TextSendMessage(text=f"éŒ¯èª¤ï¼š{error_message}"))

    except subprocess.TimeoutExpired as e:
        error_message = f"è…³æœ¬åŸ·è¡Œè¶…æ™‚ã€‚å‘½ä»¤ï¼š{e.cmd}" if current_lang == "zh" else f"Script execution timed out. Command: {e.cmd}"
        logging.error(f"Script timeout for user {user_id}: {error_message}")
        line_bot_api.push_message(user_id, TextSendMessage(text=f"éŒ¯èª¤ï¼šè¨“ç·´è…³æœ¬åŸ·è¡Œè¶…æ™‚ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–æª¢æŸ¥è¨­å®šã€‚"))

    except Exception as e:
        error_message = f"åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ï¼š{str(e)}" if current_lang == "zh" else f"An unknown error occurred during processing: {str(e)}"
        logging.error(f"Unknown error during pipeline for user {user_id}: {e}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"è™•ç†éç¨‹ä¸­å‡ºéŒ¯ï¼š{error_message}"))

    finally:
        # Clear UPLOAD_FOLDER only if it's not needed for re-uploading, i.e., after initial processing
        if os.path.exists(UPLOAD_FOLDER) and not uploading: # Only clear if not in an active upload state
            shutil.rmtree(UPLOAD_FOLDER)
            os.makedirs(UPLOAD_FOLDER)
            logging.info(f"Cleared UPLOAD_FOLDER contents after pipeline for user {user_id}.")

        user_states[user_id]['image_count'] = 0
        uploading = False 

# --- ç”Ÿæˆé è¦½åœ–ä¸¦è©¢å•æ˜¯å¦ä¸Šå‚³ ---
def generate_preview_and_ask_upload(user_id, prompt, base_model_name, lora_info):
    current_lang = user_states.get(user_id, {}).get('lang', 'zh')
    generated_image_urls = []
    try:
        # Use the provided lora_info, which contains 'local_path' if it's the newly trained one
        lora_tag = lora_info['original_name']
        lora_path_for_sd = lora_info['local_path'] if lora_info['is_local'] else None

        if not lora_path_for_sd or not os.path.exists(lora_path_for_sd):
            line_bot_api.push_message(user_id, TextSendMessage("éŒ¯èª¤ï¼šç„¡æ³•æ‰¾åˆ°ç”¨æ–¼ç”Ÿæˆé è¦½åœ–çš„ LoRA æ¨¡å‹ã€‚" if current_lang == "zh" else "Error: Could not find the LoRA model for preview generation."))
            send_main_menu(user_id)
            return

        # Ensure the base model is set
        model_path = os.path.join(MODEL_FOLDER, base_model_name)
        SD_API.util_set_model(model_path)
        SD_API.util_wait_for_ready()
        logging.info(f"SD_API model set to {base_model_name} for preview generation for user {user_id}.")

        # Add LoRA to prompt for preview
        prompt_en = GoogleTranslator(source='auto', target='en').translate(prompt) if current_lang == "zh" else prompt
        prompt_with_lora = f"<lora:{lora_tag}:0.8>, {prompt_en}"
        negative_prompt = "worst quality, low quality, blurry, nsfw, nude, naked, nipples, sex, bad anatomy, watermark, text"

        line_bot_api.push_message(user_id, TextSendMessage(f"æ­£åœ¨ä½¿ç”¨æ‚¨çš„æ–°æ¨¡å‹ **{lora_tag}** ç”Ÿæˆé è¦½åœ– (2 å¼µ)..." if current_lang == "zh" else f"Generating 2 preview images with your new model **{lora_tag}**..."))

        # Generate 2 preview images
        for i in range(2):
            result = SD_API.txt2img(
                prompt=prompt_with_lora,
                negative_prompt=negative_prompt,
                width=512,
                height=768,
                steps=20,
                cfg_scale=7,
                sampler_name="DPM++ 2M Karras",
                n_iter=1,
                seed=-1, # Use random seed for each preview
                save_images=True,
                do_not_save_grid=True,
                override_settings={"sd_model_checkpoint": base_model_name} # Ensure base model is used
            )
            
            if result.images:
                img_byte_arr = io.BytesIO()
                result.images[0].save(img_byte_arr, format='PNG')
                img_byte_arr.seek(0) # Reset stream position

                preview_filename = f"preview_{lora_tag}_{i+1}.png"
                preview_path = os.path.join(CONSOLIDATED_OUTPUT_FOLDER, preview_filename)
                with open(preview_path, 'wb') as f:
                    f.write(img_byte_arr.getvalue())
                
                logging.info(f"Generated preview image saved to {preview_path}")

                public_url = upload_to_drive_and_get_public_link(drive_service, preview_path, GOOGLE_DRIVE_OUTPUT_FOLDER_ID)
                if public_url:
                    generated_image_urls.append(public_url)
                    # Send image to user
                    line_bot_api.push_message(user_id, ImageSendMessage(original_content_url=public_url, preview_image_url=public_url))
                    logging.info(f"Sent preview image {i+1} to user {user_id}: {public_url}")
                else:
                    line_bot_api.push_message(user_id, TextSendMessage("ç„¡æ³•ä¸Šå‚³é è¦½åœ–åˆ° Google Driveã€‚" if current_lang == "zh" else "Could not upload preview image to Google Drive."))
                    logging.error(f"Failed to upload preview image {preview_filename} for user {user_id}.")

            else:
                line_bot_api.push_message(user_id, TextSendMessage(f"é è¦½åœ– {i+1} ç”Ÿæˆå¤±æ•—ã€‚" if current_lang == "zh" else f"Preview image {i+1} generation failed."))
                logging.error(f"Failed to generate preview image {i+1} for user {user_id}.")
                break # Stop if one preview fails

        if generated_image_urls:
            # Ask user if they like the model and want to upload it
            lora_path_to_upload = lora_info['local_path'] # Get the actual path for the upload button
            confirm_message = TextSendMessage(
                text="æ‚¨å°é€™äº›é è¦½åœ–æ»¿æ„å—ï¼Ÿå¦‚æœæ»¿æ„ï¼Œå¯ä»¥å°‡æ‚¨çš„ LoRA æ¨¡å‹ä¸Šå‚³åˆ° Google Driveï¼Œé€™æ¨£ä»¥å¾Œå°±å¯ä»¥éš¨æ™‚ä½¿ç”¨å®ƒç”Ÿåœ–äº†ï¼" if current_lang == "zh" else
                     "Are you satisfied with these preview images? If so, you can upload your LoRA model to Google Drive, so you can use it anytime for image generation!"
            )
            confirm_buttons = TemplateSendMessage(
                alt_text="ä¸Šå‚³ LoRA æ¨¡å‹ï¼Ÿ",
                template=ButtonsTemplate(
                    title="ä¸Šå‚³æ‚¨çš„ LoRA æ¨¡å‹ï¼Ÿ" if current_lang == "zh" else "Upload Your LoRA Model?",
                    text="é¸æ“‡æ˜¯å¦å°‡æ¨¡å‹å„²å­˜åˆ°é›²ç«¯" if current_lang == "zh" else "Choose whether to save your model to the cloud",
                    actions=[
                        PostbackAction(
                            label="æ˜¯ï¼Œä¸Šå‚³ï¼" if current_lang == "zh" else "Yes, upload!",
                            data=f"action=upload_lora&lora_path={lora_path_to_upload}"
                        ),
                        PostbackAction(
                            label="å¦ï¼Œè·³éä¸Šå‚³" if current_lang == "zh" else "No, skip upload",
                            data="action=skip_upload_lora"
                        )
                    ]
                )
            )
            line_bot_api.push_message(user_id, [confirm_message, confirm_buttons])
        else:
            line_bot_api.push_message(user_id, TextSendMessage("é è¦½åœ–ç”Ÿæˆå¤±æ•—ï¼ŒLoRA æ¨¡å‹å°‡ä¸æœƒä¸Šå‚³ã€‚æ‚¨å¯ä»¥å˜—è©¦é‡æ–°è¨“ç·´ã€‚" if current_lang == "zh" else "Preview image generation failed, LoRA model will not be uploaded. You can try retraining."))
            # Clean up the local LoRA if preview failed
            if lora_info['is_local'] and os.path.exists(lora_info['local_path']):
                os.remove(lora_info['local_path'])
                logging.info(f"Deleted local LoRA file due to preview failure: {lora_info['local_path']}")
            user_states[user_id]['latest_trained_lora_path'] = None
            user_states[user_id]['selected_lora_info'] = None
            user_states[user_id]['mode'] = 'main_menu'
            send_main_menu(user_id) # Go back to main menu


    except Exception as e:
        logging.error(f"Error during preview generation for user {user_id}: {e}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(f"ç”Ÿæˆé è¦½åœ–æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}" if current_lang == "zh" else f"An error occurred during preview generation: {str(e)}"))
        # Clean up local LoRA if any error during preview
        if lora_info['is_local'] and os.path.exists(lora_info['local_path']):
            os.remove(lora_info['local_path'])
            logging.info(f"Deleted local LoRA file due to error during preview: {lora_info['local_path']}")
        user_states[user_id]['latest_trained_lora_path'] = None
        user_states[user_id]['selected_lora_info'] = None
        user_states[user_id]['mode'] = 'main_menu'
        send_main_menu(user_id) # Go back to main menu

    finally:
        # Clean up generated preview images from local storage after they are uploaded/handled
        if os.path.exists(CONSOLIDATED_OUTPUT_FOLDER):
            for f in os.listdir(CONSOLIDATED_OUTPUT_FOLDER):
                os.remove(os.path.join(CONSOLIDATED_OUTPUT_FOLDER, f))
            logging.info(f"Cleared CONSOLIDATED_OUTPUT_FOLDER contents after preview for user {user_id}.")


# --- ç¨ç«‹çš„ LoRA ä¸Šå‚³åˆ° Google Drive å‡½æ•¸ (for threading) ---
def upload_lora_to_drive_thread(user_id, lora_path_to_upload):
    current_lang = user_states.get(user_id, {}).get('lang', 'zh')
    drive_service_thread = authenticate_google_drive() # Get a new service instance for the thread
    if not drive_service_thread:
        line_bot_api.push_message(user_id, TextSendMessage(text="âŒ ç„¡æ³•é€£æ¥åˆ° Google Drive æœå‹™ï¼ŒLoRA æ¨¡å‹ä¸Šå‚³å¤±æ•—ã€‚"))
        return

    try:
        uploaded_lora_url = upload_to_drive_and_get_public_link(
            drive_service_thread, lora_path_to_upload, GOOGLE_DRIVE_LORA_MODELS_FOLDER_ID
        )

        if uploaded_lora_url:
            lora_filename = os.path.basename(lora_path_to_upload)
            line_bot_api.push_message(user_id, TextSendMessage(f"æ‚¨çš„ LoRA æ¨¡å‹ **{lora_filename}** å·²æˆåŠŸä¸Šå‚³åˆ° Google Driveï¼æ‚¨ç¾åœ¨å¯ä»¥åœ¨ã€Œæˆ‘çš„ LoRA æ¨¡å‹ã€ä¸­é¸æ“‡å®ƒä¾†ç”Ÿåœ–äº†ã€‚\né€£çµï¼š{uploaded_lora_url}" if current_lang == "zh" else f"Your LoRA model **{lora_filename}** has been successfully uploaded to Google Drive! You can now select it from 'My LoRA Models' to generate images.\nLink: {uploaded_lora_url}"))
            logging.info(f"Uploaded {lora_filename} to Google Drive from preview confirmation. Public link: {uploaded_lora_url}")
        else:
            line_bot_api.push_message(user_id, TextSendMessage("LoRA æ¨¡å‹ä¸Šå‚³ Google Drive å¤±æ•—ã€‚è«‹è¯çµ¡ç®¡ç†å“¡ã€‚" if current_lang == "zh" else "Failed to upload LoRA model to Google Drive. Please contact the administrator."))

    except Exception as e:
        logging.error(f"Error uploading LoRA model {lora_path_to_upload} to Drive: {e}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(f"ä¸Šå‚³ LoRA æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}" if current_lang == "zh" else f"An error occurred while uploading LoRA model: {str(e)}"))
    finally:
        # Always clean up the local LoRA model after upload attempt
        if os.path.exists(lora_path_to_upload):
            os.remove(lora_path_to_upload)
            logging.info(f"Deleted local trained LoRA file after upload attempt: {lora_path_to_upload}")
        # Reset the state related to the latest trained LoRA
        user_states[user_id]['latest_trained_lora_path'] = None
        user_states[user_id]['selected_lora_info'] = None
        user_states[user_id]['mode'] = 'main_menu'
        send_main_menu(user_id) # Return to main menu after process


# --- åŸ·è¡Œ Stable Diffusion ç”Ÿåœ–æµç¨‹ (è€ƒæ…® LoRA ä¸‹è¼‰) ---
def run_sd_generation(user_id, prompt, base_model_name, selected_lora_info, reply_token):
    # ...
    command = [
        'python3',
        GENERATE_SCRIPT,
        '--prompt', prompt,
        '--output_dir', GENERATED_IMAGES_OUTPUT_FOLDER,
        '--model_name', base_model_name
    ]

    if selected_lora_info and (selected_lora_info.get('is_local') or selected_lora_info.get('file_id')):
        # è™•ç† LoRA æ¨¡å‹è·¯å¾‘ï¼Œç¢ºä¿æ˜¯æœ¬åœ°æª”æ¡ˆè·¯å¾‘
        lora_path_for_generation = None
        if selected_lora_info.get('is_local') and selected_lora_info.get('local_path'):
            lora_path_for_generation = selected_lora_info['local_path']
        elif selected_lora_info.get('file_id'): # LoRA å¾ Google Drive ä¸‹è¼‰è€Œä¾†
            lora_filename_with_ext = selected_lora_info['original_name']
            if not (lora_filename_with_ext.endswith('.safetensors') or lora_filename_with_ext.endswith('.pt')):
                lora_filename_with_ext += '.safetensors' # ç¢ºä¿å‰¯æª”å
            
            download_path = os.path.join(SD_LORA_DOWNLOAD_FOLDER, lora_filename_with_ext)
            
            if not os.path.exists(download_path):
                # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œå‰‡å¾ Google Drive ä¸‹è¼‰
                line_bot_api.push_message(user_id, TextSendMessage(text=f"æ­£åœ¨ä¸‹è¼‰ LoRA æ¨¡å‹ {selected_lora_info['name']}..." if current_lang == "zh" else f"Downloading LoRA model {selected_lora_info['name']}..."))
                if download_file_from_drive(drive_service, selected_lora_info['file_id'], download_path):
                    lora_path_for_generation = download_path
                else:
                    logging.error(f"Failed to download LoRA model {selected_lora_info['name']} (ID: {selected_lora_info['file_id']}).")
                    line_bot_api.push_message(user_id, TextSendMessage(text="ä¸‹è¼‰ LoRA æ¨¡å‹å¤±æ•—ï¼Œè«‹é‡è©¦æˆ–é¸æ“‡å…¶ä»–æ¨¡å‹ã€‚" if current_lang == "zh" else "Failed to download LoRA model. Please try again or select another model."))
                    return # çµ‚æ­¢ç”Ÿæˆ

            else: # æª”æ¡ˆå·²å­˜åœ¨æœ¬åœ°
                lora_path_for_generation = download_path
                logging.info(f"LoRA model {selected_lora_info['name']} already exists locally: {download_path}")

        if lora_path_for_generation:
            command.extend(['--lora_path', lora_path_for_generation])
        else:
            logging.warning(f"No valid LoRA path for generation, LoRA will not be applied.")

    # åŸ·è¡Œä½ çš„ç”Ÿåœ–ç¨‹å¼
    result = subprocess.run(command, check=True, capture_output=True, text=True, cwd=TRAIN_SCRIPT_DIR)
    # ... è™•ç†ç”Ÿæˆçš„åœ–ç‰‡ä¸¦ç™¼é€çµ¦ç”¨æˆ¶

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)