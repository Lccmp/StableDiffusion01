import os
import shutil
import subprocess
import threading
import torch
import io
import json
import time
import logging
import traceback

from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage, ImageMessage, ImageSendMessage,
    TemplateSendMessage, ButtonsTemplate, PostbackAction, PostbackEvent, FlexSendMessage,
    BubbleContainer, BoxComponent, TextComponent, ButtonComponent, MessageAction, SeparatorComponent
)

from webuiapi import WebUIApi
from deep_translator import GoogleTranslator 

# åŒ¯å…¥ Google Drive ç›¸é—œæ¨¡çµ„
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from googleapiclient.errors import HttpError # ç¢ºä¿å¼•å…¥ HttpError

app = Flask(__name__)

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === LINE Bot è¨­å®š ===
LINE_CHANNEL_ACCESS_TOKEN = 'QMGBL9q4N8kA408b053UMjyiGkIeNGI5KEWqgsu/LRqwXqktaAxqAa1uce4o6IwLI8klVgipLcdZ8Ey00LLkJTMFUg7GQ3fyJ2uvruGL4SKZ16GKeMSo2lyV1K/D4Sg0A7XwPVj8FUXmd9sTCyxeLgdB04t89/1O/w1cDnyilFU='
LINE_CHANNEL_SECRET = '3bb0908c9e23799bbaba57be1e638e35'

line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# === è³‡æ–™å¤¾èˆ‡è…³æœ¬è·¯å¾‘è¨­å®š ===
UPLOAD_FOLDER = '/home/user/lora-train/lora-scripts/linebot_images/20_chien' # åœ–ç‰‡è¨“ç·´æš«å­˜è·¯å¾‘
TAGGER_PYTHON = '/home/user/lora-train/tagger/venv/bin/python3' # æ¨™è¨»è…³æœ¬çš„Pythonè§£é‡‹å™¨è·¯å¾‘
TAGGING_SCRIPT = '/home/user/lora-train/tagger/phi3_fast.py' # æ¨™è¨»è…³æœ¬è·¯å¾‘
TRAIN_SCRIPT = '/home/user/lora-train/lora-scripts/train-t1-Copy2.sh' # è¨“ç·´è…³æœ¬è·¯å¾‘
TRAIN_SCRIPT_DIR = '/home/user/lora-train/lora-scripts' # è¨“ç·´è…³æœ¬æ‰€åœ¨ç›®éŒ„
LORA_MODELS_INFO_FILE = 'user_lora_models.json'
LORA_DOWNLOADED_MODELS_FOLDER = "/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Lora/Downloaded_Models/"
# === ç”Ÿåœ–è…³æœ¬è¨­å®š ===
GENERATE_SCRIPT = '/home/user/lora-train/lora-scripts/stable-diffusion-webui/chien-generate_random_seeds.py'
GENERATED_IMAGES_OUTPUT_FOLDER = "/home/user/lora-train/lora-scripts/random_output"

# === Stable Diffusion API è¨­å®š ===
SD_API = WebUIApi(host="127.0.0.1", port=7860) # è«‹ç¢ºä¿æ‚¨çš„ Stable Diffusion WebUI å·²åœ¨ 7860 åŸ é‹è¡Œ
MODEL_FOLDER = "/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Stable-diffusion" # æ‚¨çš„ Stable Diffusion æ¨¡å‹è³‡æ–™å¤¾



DEFAULT_SD_MODEL_FOR_LORA_GEN = "chilloutmix_NiPrunedFp32Fix.safetensors"

# é€™æ˜¯ä½ å¸Œæœ› LoRA ç”Ÿæˆåœ–ç‰‡æ™‚ä½¿ç”¨çš„é è¨­æç¤ºè©
# é€šå¸¸æ˜¯ä½ è¨“ç·´ LoRA æ™‚å¸¸ç”¨çš„åŸºç¤æç¤ºè©ï¼Œæˆ–æ˜¯ä¸€å€‹é€šç”¨çš„æ­£é¢æç¤ºè©
DEFAULT_PROMPT_FOR_LORA_GEN = "masterpiece, best quality, ultra detailed, 1girl, solo"
# --- æ–°å¢ï¼šæ¨¡å‹é¢¨æ ¼æ˜ å°„ ---
MODEL_STYLES = {
    "anything-v5.safetensors": "å‹•æ¼«é¢¨æ ¼",
    "chilloutmix_NiPrunedFp32Fix.safetensors": "å¯«å¯¦é¢¨æ ¼",
    "Deliberate_v6.safetensors":"æ’ç•«é¢¨æ ¼",
    "Classic_disney_Style__Illustrious.safetensors":"è¿ªå£«å°¼é¢¨æ ¼",
    "v1-5-pruned-emaonly.safetensors": "ä¸€èˆ¬é¢¨æ ¼",
}

# === Google Drive è¨­å®š ===
GOOGLE_DRIVE_GENERATED_IMAGES_FOLDER_ID = "1_9QLHupRK8e-CjfLh70mNdesVIuvemZ1" # è¨“ç·´å¾Œè‡ªå‹•ç”Ÿåœ–ä¸Šå‚³çš„è³‡æ–™å¤¾ ID
GOOGLE_DRIVE_SD_OUTPUT_FOLDER_ID = "1_9QLHupRK8e-CjfLh70mNdesVIuvemZ1" # æ‰‹å‹•ç”Ÿåœ–ä¸Šå‚³çš„è³‡æ–™å¤¾ ID
SCOPES = ["https://www.googleapis.com/auth/drive"]
SERVICE_ACCOUNT_FILE = "/home/user/lora-train/elite-mix-441517-k7-618329de7f11.json" # æœå‹™å¸³æˆ¶é‡‘é‘°è·¯å¾‘

# ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(GENERATED_IMAGES_OUTPUT_FOLDER, exist_ok=True)
os.makedirs("output", exist_ok=True) # ç‚º webuiapi ç”Ÿæˆçš„åœ–ç‰‡æº–å‚™

# å…¨åŸŸç‹€æ…‹è®Šæ•¸
uploading = False # ç”¨æ–¼æ§åˆ¶åœ–ç‰‡è¨“ç·´æ¨¡å¼ä¸‹çš„åœ–ç‰‡ä¸Šå‚³
user_id_for_process = None # ç”¨æ–¼è¨˜éŒ„è§¸ç™¼è¨“ç·´æµç¨‹çš„ç”¨æˆ¶ ID
image_count_lock = threading.Lock()
user_states = {} # ç”¨æ–¼å„²å­˜æ¯å€‹ç”¨æˆ¶çš„ç‹€æ…‹
save_user_lora_models = {}

if not os.path.exists(LORA_MODELS_INFO_FILE):
    with open(LORA_MODELS_INFO_FILE, 'w') as f:
        json.dump({}, f)

def load_user_lora_models():
    """è¼‰å…¥ä½¿ç”¨è€…å·²ä¿å­˜çš„ LoRA æ¨¡å‹è³‡è¨Š"""
    try:
        with open(LORA_MODELS_INFO_FILE, 'r') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError:
        logging.error(f"Error decoding {LORA_MODELS_INFO_FILE}. Returning empty dict.")
        return {}

def save_user_lora_models(data):
    """ä¿å­˜ä½¿ç”¨è€…å·²ä¿å­˜çš„ LoRA æ¨¡å‹è³‡è¨Š"""
    try:
        with open(LORA_MODELS_INFO_FILE, 'w') as f:
            json.dump(data, f, indent=4)
    except Exception as e:
        logging.error(f"Error saving {LORA_MODELS_INFO_FILE}: {e}")


user_saved_lora_models = load_user_lora_models()
logging.info(f"Loaded user LoRA models: {user_saved_lora_models}")
# === Google Drive èªè­‰åˆå§‹åŒ–å‡½æ•¸ ===
def authenticate_google_drive():
    try:
        creds = service_account.Credentials.from_service_account_file(
            SERVICE_ACCOUNT_FILE, scopes=SCOPES
        )
        service = build('drive', 'v3', credentials=creds)
        logging.info("Google Drive èªè­‰æˆåŠŸï¼")
        return service
    except Exception as e:
        logging.error(f"Google Drive èªè­‰å¤±æ•—: {e}")
        return None

# åˆå§‹åŒ– Google Drive æœå‹™ (æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚èªè­‰ä¸€æ¬¡)
drive_service = authenticate_google_drive()
if not drive_service:
    logging.critical("ğŸš¨ Google Drive æœå‹™åˆå§‹åŒ–å¤±æ•—ï¼Œç¨‹å¼å°‡ç„¡æ³•ä¸Šå‚³æª”æ¡ˆã€‚è«‹æª¢æŸ¥æœå‹™å¸³æˆ¶é‡‘é‘°ã€‚")
    # å¦‚æœ Google Drive æ˜¯é—œéµåŠŸèƒ½ï¼Œé€™è£¡å¯ä»¥é¸æ“‡ abort(500) æˆ–å…¶ä»–è™•ç†æ–¹å¼

# --- ä¸Šå‚³åœ–ç‰‡åˆ° Google Drive ä¸¦ç²å–å…¬é–‹é€£çµå‡½æ•¸ ---
def upload_to_drive_and_get_public_link(service, file_path, folder_id):
    try:
        file_metadata = {
            'name': os.path.basename(file_path),
            'parents': [folder_id]
        }
        media = MediaFileUpload(file_path, resumable=True)
        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()
        file_id = file.get('id')

        permission = {
            'type': 'anyone',
            'role': 'reader'
        }
        service.permissions().create(fileId=file_id, body=permission, fields='id').execute()

        file_info = service.files().get(fileId=file_id, fields='webContentLink,webViewLink').execute()
        public_link = file_info.get('webContentLink') # ç›´æ¥ä¸‹è¼‰é€£çµ
        if not public_link:
            public_link = file_info.get('webViewLink') # ç€è¦½é€£çµ
            # å°æ–¼ Line botï¼Œæœ‰æ™‚éœ€è¦å°‡ "view" é€£çµè½‰æ›ç‚º "uc?export=download" æ‰èƒ½ç›´æ¥é¡¯ç¤º
            if public_link and "view" in public_link:
                public_link = public_link.replace("/view", "/uc?export=download")

        if public_link:
            logging.info(f"Uploaded {os.path.basename(file_path)} to Google Drive. Public link: {public_link}")
            return public_link
        else:
            logging.error(f"Failed to get public link for file {file_path}.")
            return None
    except HttpError as error:
        logging.error(f"An error occurred during Google Drive upload: {error}", exc_info=True)
        return None

# === å·¥å…·å‡½å¼ ===
def list_models():
    """åˆ—å‡º Stable Diffusion æ¨¡å‹è³‡æ–™å¤¾ä¸­çš„æ¨¡å‹åç¨± (åªåˆ—å‡º .safetensors æª”æ¡ˆ)"""
    try:
        models = [f for f in os.listdir(MODEL_FOLDER) if f.endswith(".safetensors")]
        # ç¯©é¸æ‰ä¸€äº›éæ¨¡å‹æª”æ¡ˆæˆ–ç‰¹æ®Šæª”æ¡ˆ
        models = [m for m in models if "Put Stable Diffusion checkpoints here.txt" not in m]
        return models
    except Exception as e:
        logging.error(f"ç„¡æ³•åˆ—å‡º Stable Diffusion æ¨¡å‹: {e}")
        return []

def send_main_menu(user_id):
    """å‚³é€ä¸»åŠŸèƒ½é¸å–®çµ¦ä½¿ç”¨è€… (Flex Message ç‰ˆæœ¬ï¼Œåªä¿ç•™ç”Ÿåœ–å’Œåœ–ç‰‡è¨“ç·´)"""
    flex_message = {
        "type": "bubble",
        "size": "mega",
        "body": {
            "type": "box",
            "layout": "vertical",
            "spacing": "md",
            "contents": [
                {
                    "type": "text",
                    "text": "è«‹é¸æ“‡åŠŸèƒ½",
                    "weight": "bold",
                    "size": "xl",
                    "align": "center"
                },
                {
                    "type": "button",
                    "style": "primary",
                    "color": "#FF69B4", # ç²‰ç´…è‰²
                    "action": {"type": "message", "label": "ç”Ÿåœ–åŠŸèƒ½", "text": "ç”Ÿåœ–åŠŸèƒ½"}
                },
                {
                    "type": "button",
                    "style": "primary",
                    "color": "#4A90E2", # è—è‰²
                    "action": {"type": "message", "label": "åœ–ç‰‡è¨“ç·´åŠŸèƒ½", "text": "åœ–ç‰‡è¨“ç·´åŠŸèƒ½"}
                },
                # æ–°å¢ã€Œæˆ‘çš„æ¨¡å‹ã€æŒ‰éˆ•
                {
                    "type": "button",
                    "style": "secondary", # æ¬¡è¦æŒ‰éˆ•æ¨£å¼
                    "color": "#E6CCFF", # ç¶ è‰²
                    "action": {"type": "message", "label": "æˆ‘çš„æ¨¡å‹", "text": "æˆ‘çš„æ¨¡å‹"}
                }
            ]
        }
    }
    line_bot_api.push_message(user_id, FlexSendMessage(alt_text="è«‹é¸æ“‡åŠŸèƒ½", contents=flex_message))
    logging.info(f"User {user_id} received main menu.")
# === Webhook æ¥æ”¶ ===
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers["X-Line-Signature"]
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        logging.error("Invalid signature. Please check your channel access token/channel secret.")
        abort(400)
    except Exception as e:
        logging.error(f"Line Bot Error: {e}", exc_info=True)
        abort(400)
    return "OK"

# === è™•ç†æ–‡å­—è¨Šæ¯ ===
@handler.add(MessageEvent, message=TextMessage)
def handle_text(event):
    global uploading, user_id_for_process, user_saved_lora_models # ç¢ºä¿èƒ½ä¿®æ”¹å…¨åŸŸè®Šæ•¸
    user_id = event.source.user_id
    message_text = event.message.text.strip()

    # åˆå§‹åŒ–ç”¨æˆ¶ç‹€æ…‹ï¼Œå¦‚æœä¸å­˜åœ¨
    if user_id not in user_states:
        user_states[user_id] = {
            'mode': 'initial_welcome', # æ–°å¢åˆå§‹æ­¡è¿æ¨¡å¼ï¼Œç¢ºä¿åªç™¼é€ä¸€æ¬¡æ­¡è¿èª
            'image_count': 0,
            'prompt': None,
            'lang': 'zh', # é è¨­ä¸­æ–‡
            'processed_message_ids': set(),
            'selected_sd_model': None,
            'lora_to_name_path': None # æ–°å¢ï¼šç­‰å¾…å‘½åçš„ LoRA æ¨¡å‹è·¯å¾‘
        }

    # åˆå§‹æ­¡è¿è¨Šæ¯é‚è¼¯
    if user_states[user_id]['mode'] == 'initial_welcome':
        initial_welcome_message_zh = "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„å°ˆå±¬ AI ç¹ªåœ–å°å¹«æ‰‹ï¼Œå¯ä»¥å”åŠ©æ‚¨ç”Ÿåœ–æˆ–è¨“ç·´æ¨¡å‹ã€‚è«‹è¼¸å…¥ 'menu' æŸ¥çœ‹åŠŸèƒ½é¸å–®ã€‚"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=initial_welcome_message_zh))
        user_states[user_id]['mode'] = 'main_menu' # ç™¼é€å¾Œå³åˆ‡æ›åˆ°ä¸»é¸å–®æ¨¡å¼
        logging.info(f"Sent initial welcome message to user {user_id}.")
        return # é¿å…åœ¨ç™¼é€æ­¡è¿èªå¾Œç«‹å³è™•ç†å…¶ä»–æŒ‡ä»¤

    current_state = user_states[user_id]
    current_mode = current_state['mode']
    current_lang = current_state['lang']

    logging.info(f"User {user_id} in mode '{current_mode}' sent text: '{message_text}'")

    # --- ä¸»é¸å–®æŒ‡ä»¤ ---
    if message_text == "menu" or message_text == "é¸å–®":
        send_main_menu(user_id)
        current_state['mode'] = 'main_menu'
        current_state['prompt'] = None # æ¸…é™¤ä¹‹å‰çš„ç”Ÿåœ–æç¤ºè©
        current_state['selected_sd_model'] = None # æ¸…é™¤å·²é¸æ“‡çš„æ¨¡å‹
        current_state['image_count'] = 0 # æ¸…é™¤è¨“ç·´è¨ˆæ•¸
        current_state['lora_to_name_path'] = None # æ¸…é™¤å¾…å‘½åæ¨¡å‹
        uploading = False # ç¢ºä¿é€€å‡ºä¸Šå‚³æ¨¡å¼
        return

    # --- èªè¨€åˆ‡æ›æŒ‡ä»¤ ---
    if message_text.lower() in ["ä¸­æ–‡", "chinese"]:
        current_state['lang'] = "zh"
        line_bot_api.reply_message(event.reply_token, TextSendMessage("èªè¨€å·²åˆ‡æ›ç‚ºä¸­æ–‡ï¼"))
        return
    elif message_text.lower() in ["è‹±æ–‡", "english"]:
        current_state['lang'] = "en"
        line_bot_api.reply_message(event.reply_token, TextSendMessage("Language switched to English!"))
        return

    # --- é€²å…¥ã€Œåœ–ç‰‡è¨“ç·´åŠŸèƒ½ã€æ¨¡å¼ ---
    if message_text == "åœ–ç‰‡è¨“ç·´åŠŸèƒ½":
        if not uploading: # åªæœ‰ç•¶æ²’æœ‰å…¶ä»–è¨“ç·´åœ¨é€²è¡Œæ™‚æ‰å•Ÿå‹•
            # æ¸…ç†èˆŠè³‡æ–™å¤¾ (åœ¨å•Ÿç”¨æ¨¡å¼æ™‚æ¸…é™¤ï¼Œè€Œä¸æ˜¯æ¯æ¬¡è™•ç†åœ–ç‰‡æ™‚)
            if os.path.exists(UPLOAD_FOLDER):
                try:
                    shutil.rmtree(UPLOAD_FOLDER)
                    logging.info(f"Cleared old UPLOAD_FOLDER for user {user_id}.")
                except OSError as e:
                    logging.error(f"Error clearing UPLOAD_FOLDER: {e}")
                    line_bot_api.reply_message(event.reply_token, TextSendMessage(f"ç„¡æ³•æ¸…ç†èˆŠçš„åœ–ç‰‡è¨“ç·´è³‡æ–™å¤¾ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚éŒ¯èª¤: {e}" if current_lang == "zh" else f"Could not clear old image training folder. Error: {e}"))
                    return

            os.makedirs(UPLOAD_FOLDER)

            current_state['mode'] = 'image_training'
            current_state['image_count'] = 0
            uploading = True # è¨­å®šå…¨åŸŸä¸Šå‚³æ¨™èªŒ
            user_id_for_process = user_id # è¨˜éŒ„è§¸ç™¼ç”¨æˆ¶
            reply_text = "è«‹é–‹å§‹å‚³é€åœ–ç‰‡ï¼ï¼ˆå…± 20 å¼µï¼‰" if current_lang == "zh" else "Please start sending images! (20 images in total)"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            logging.info(f"User {user_id} entered image training mode.")
        else:
            reply_text = "ç›®å‰å·²æœ‰åœ–ç‰‡è¨“ç·´æµç¨‹æ­£åœ¨é€²è¡Œä¸­ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚" if current_lang == "zh" else "An image training process is currently in progress, please try again later."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    # --- é€²å…¥ã€Œç”Ÿåœ–åŠŸèƒ½ã€æ¨¡å¼ ---
    if message_text == "ç”Ÿåœ–åŠŸèƒ½":
        current_state['mode'] = 'image_generation'
        current_state['prompt'] = None # æ¸…é™¤èˆŠçš„æç¤ºè©
        current_state['selected_sd_model'] = None # æ¸…é™¤å·²é¸æ“‡çš„æ¨¡å‹
        reply_text = "è«‹è¼¸å…¥æ‚¨çš„æç¤ºè© (Positive Prompt)ï¼" if current_lang == "zh" else "Please enter your prompt (Positive Prompt)!"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} entered image generation mode.")
        return

    # --- é€²å…¥ã€Œæˆ‘çš„æ¨¡å‹ã€æ¨¡å¼ ---
    if message_text == "æˆ‘çš„æ¨¡å‹":
        current_state['mode'] = 'my_models'
        user_loras = user_saved_lora_models.get(user_id, {})
        if not user_loras:
            reply_text = "æ‚¨å°šæœªä¿å­˜ä»»ä½•æ¨¡å‹ã€‚è«‹å…ˆé€²è¡Œåœ–ç‰‡è¨“ç·´ä¸¦ä¿å­˜æ¨¡å‹ã€‚" if current_lang == "zh" else "You haven't saved any models yet. Please train and save a model first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return

        model_buttons = []
        for model_display_name, model_file_path in user_loras.items():
            model_buttons.append(
                ButtonComponent(
                    style='primary',
                    color='#8A2BE2', # ç´«è‰²æŒ‰éˆ•
                    action=PostbackAction(label=model_display_name, data=f"action=select_my_lora&model_path={model_file_path}") # å‚³éå¯¦éš›æ¨¡å‹è·¯å¾‘
                )
            )

        flex_message_content = BubbleContainer(
            direction='ltr',
            header=BoxComponent(
                layout='vertical',
                contents=[
                    TextComponent(text="è«‹é¸æ“‡æ‚¨çš„æ¨¡å‹", weight='bold', size='xl', align='center')
                ]
            ),
            body=BoxComponent(
                layout='vertical',
                spacing='md',
                contents=model_buttons
            )
        )
        line_bot_api.reply_message(event.reply_token, FlexSendMessage(alt_text="é¸æ“‡æˆ‘çš„æ¨¡å‹", contents=flex_message_content))
        logging.info(f"User {user_id} entered 'my models' mode and received model list.")
        return

    # --- è™•ç†ã€Œåœ–ç‰‡è¨“ç·´åŠŸèƒ½ã€æ¨¡å¼ä¸‹çš„æ–‡å­—è¨Šæ¯ ---
    if current_mode == 'image_training':
        reply_text = f"æ‚¨ç›®å‰åœ¨åœ–ç‰‡è¨“ç·´æ¨¡å¼ã€‚è«‹ç¹¼çºŒä¸Šå‚³åœ–ç‰‡ï¼Œç›®å‰å·²ä¸Šå‚³ {current_state['image_count']} å¼µã€‚" if current_lang == "zh" else f"You are in image training mode. Please continue uploading images. Current: {current_state['image_count']} images."
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    # --- è™•ç†ã€Œç”Ÿåœ–åŠŸèƒ½ã€æ¨¡å¼ä¸‹çš„æ–‡å­—è¨Šæ¯ (è¼¸å…¥æç¤ºè©) ---
    if current_mode == 'image_generation':
        if current_state['prompt'] is None: # å¦‚æœé‚„æ²’æœ‰æç¤ºè©ï¼Œå‰‡å„²å­˜ä¸¦è¦æ±‚é¸æ“‡æ¨¡å‹
            current_state['prompt'] = message_text

            model_files = list_models() # ç²å–æ‰€æœ‰ Stable Diffusion æ¨¡å‹æª”æ¡ˆåç¨±

            # æº–å‚™æ¨¡å‹é¸æ“‡æŒ‰éˆ•åˆ—è¡¨
            model_buttons = []
            for model_file in model_files:
                # ä½¿ç”¨ MODEL_STYLES ç²å–é¢¨æ ¼åç¨±ï¼Œå¦‚æœæ²’æœ‰å‰‡ç”¨æª”æ¡ˆåç¨±ä½œç‚ºå‚™ç”¨
                style_name = MODEL_STYLES.get(model_file, model_file.replace(".safetensors", ""))

                model_buttons.append(
                    ButtonComponent(
                        style='primary',
                        color='#66CCFF', # è—è‰²æŒ‰éˆ•
                        action=PostbackAction(label=style_name, data=f"action=select_sd_model&model_name={model_file}") # å¯¦éš›å‚³éæª”æ¡ˆåç¨±
                    )
                )

            if not model_buttons:
                reply_text = "ç›®å‰æ²’æœ‰å¯ç”¨çš„ Stable Diffusion æ¨¡å‹æª”æ¡ˆã€‚è«‹è¯ç¹«ç®¡ç†å“¡ã€‚" if current_lang == "zh" else "No Stable Diffusion model files found. Please contact the administrator."
                line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
                return

            # ä½¿ç”¨ Flex Message å±•ç¤ºæ¨¡å‹é¸æ“‡æŒ‰éˆ•
            flex_message_content = BubbleContainer(
                direction='ltr',
                header=BoxComponent(
                    layout='vertical',
                    contents=[
                        TextComponent(text="è«‹é¸æ“‡æ¨¡å‹é¢¨æ ¼", weight='bold', size='xl', align='center')
                    ]
                ),
                body=BoxComponent(
                    layout='vertical',
                    spacing='md',
                    contents=model_buttons
                )
            )
            line_bot_api.reply_message(event.reply_token, FlexSendMessage(alt_text="é¸æ“‡æ¨¡å‹é¢¨æ ¼", contents=flex_message_content))
            logging.info(f"User {user_id} entered prompt: '{message_text}', awaiting model selection.")
        else: # å¦‚æœå·²ç¶“æœ‰æç¤ºè©ï¼Œä½†åˆè¼¸å…¥æ–‡å­—ï¼Œå‰‡æç¤ºé¸æ“‡æ¨¡å‹
            reply_text = "è«‹å…ˆé¸æ“‡æ¨¡å‹é¢¨æ ¼ã€‚" if current_lang == "zh" else "Please choose a model style first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        return

    # --- è™•ç†å‘½å LoRA æ¨¡å‹çš„æ–‡å­—è¨Šæ¯ ---
    if current_mode == 'name_lora_model':
        lora_display_name = message_text.strip()
        lora_path = current_state.get('lora_to_name_path')
        if lora_path and lora_display_name:
            # å„²å­˜æ¨¡å‹åç¨±èˆ‡è·¯å¾‘å°æ‡‰é—œä¿‚
            if user_id not in user_saved_lora_models:
                user_saved_lora_models[user_id] = {}
            user_saved_lora_models[user_id][lora_display_name] = lora_path
            save_user_lora_models(user_saved_lora_models)
            reply_text = f"æ¨¡å‹ '{lora_display_name}' å·²æˆåŠŸä¿å­˜ï¼" if current_lang == "zh" else f"Model '{lora_display_name}' saved successfully!"
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            logging.info(f"User {user_id} saved LoRA model '{lora_display_name}' at '{lora_path}'")
        else:
            reply_text = "å‘½åæ¨¡å‹å¤±æ•—ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚" if current_lang == "zh" else "Failed to name model, please try again later."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

        current_state['lora_to_name_path'] = None
        current_state['mode'] = 'main_menu'
        return


    # --- é è¨­å›è¦†ï¼šä¸åœ¨ä»»ä½•ç‰¹å®šæ¨¡å¼ä¸‹ï¼Œæç¤ºä¸»é¸å–® ---
    reply_text = "è«‹è¼¸å…¥ 'menu' æŸ¥çœ‹åŠŸèƒ½é¸å–®ã€‚" if current_lang == "zh" else "Please type 'menu' to see the function menu."
    line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))

# === è™•ç†åœ–ç‰‡è¨Šæ¯ (åœ–ç‰‡è¨“ç·´æ¨¡å¼å°ˆç”¨) ===
@handler.add(MessageEvent, message=ImageMessage)
def handle_image(event):
    global uploading, user_id_for_process
    user_id = event.source.user_id

    # ç¢ºä¿ç”¨æˆ¶è™•æ–¼åœ–ç‰‡è¨“ç·´æ¨¡å¼ä¸”å…è¨±ä¸Šå‚³
    if user_id not in user_states or user_states[user_id]['mode'] != 'image_training' or not uploading:
        logging.info(f"Received image from {user_id} but not in image training mode or uploading state. Ignoring.")
        return

    current_state = user_states[user_id]
    current_lang = current_state['lang']

    # æª¢æŸ¥æ˜¯å¦å·²è™•ç†éæ­¤è¨Šæ¯IDï¼Œé¿å…é‡è¤‡è™•ç†
    if event.message.id in current_state['processed_message_ids']:
        logging.info(f"Duplicate message ID {event.message.id} for user {user_id}. Ignoring.")
        return
    current_state['processed_message_ids'].add(event.message.id)

    # === æ ¸å¿ƒä¿®æ”¹ï¼šä½¿ç”¨é–ä¾†ä¿è­·è¨ˆæ•¸å™¨ ===
    with image_count_lock:
        current_count_in_state = current_state['image_count']

        if current_count_in_state >= 20:
            logging.info(f"User {user_id} tried to upload more than 20 images. Current (state): {current_count_in_state}. Ignoring.")
            # ä¸å†å›è¦†ï¼Œå› ç‚ºå¯èƒ½æ­£åœ¨è¨“ç·´æˆ–å·²å®Œæˆ
            return

        new_index = current_count_in_state + 1
        filename = f"{new_index:02d}.png"
        image_path = os.path.join(UPLOAD_FOLDER, filename)

        try:
            image_content = line_bot_api.get_message_content(event.message.id)
            with open(image_path, 'wb') as f:
                for chunk in image_content.iter_content():
                    f.write(chunk)

            logging.info(f"User {user_id} saved image {filename}. Total (state): {new_index}")
            current_state['image_count'] = new_index

            if new_index == 20:
                logging.info(f"User {user_id} received 20 images, preparing to start tagging, training, and generation.")
                uploading = False # åœæ­¢ä¸Šå‚³æ¨¡å¼
                current_state['mode'] = 'main_menu' # å®Œæˆå¾Œå›åˆ°ä¸»é¸å–®æ¨¡å¼
                current_state['processed_message_ids'].clear() # æ¸…ç©ºå·²è™•ç†çš„è¨Šæ¯ID
                
                # ç¢ºä¿åªæœ‰è§¸ç™¼è¨“ç·´çš„ç”¨æˆ¶æ‰èƒ½å•Ÿå‹•å®Œæ•´æµç¨‹
                if user_id_for_process == user_id:
                    threading.Thread(target=run_full_pipeline, args=(user_id,)).start()
                    reply_text = "å·²æ”¶åˆ°æ‰€æœ‰ 20 å¼µåœ–ç‰‡ã€‚é–‹å§‹æ¨™è¨»èˆ‡è¨“ç·´ï¼Œé€™éœ€è¦ä¸€äº›æ™‚é–“ï¼Œå®Œæˆå¾Œæœƒé€šçŸ¥æ‚¨ã€‚" if current_lang == "zh" else "All 20 images received. Starting tagging and training, this will take some time. You will be notified when complete."
                    line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))
                else:
                    logging.warning(f"Unexpected user_id_for_process mismatch. Expected {user_id}, got {user_id_for_process}")
                    line_bot_api.push_message(user_id, TextSendMessage(text="ç³»çµ±å…§éƒ¨éŒ¯èª¤ï¼šç„¡æ³•å•Ÿå‹•è¨“ç·´æµç¨‹ã€‚" if current_lang == "zh" else "Internal system error: Unable to start training process."))
            # --- é€™è£¡ä¸å†æœ‰ else å€å¡Šä¾†å›è¦†æ¯å¼µåœ–ç‰‡é€²åº¦ ---
            # å› ç‚º LINE çš„ push_message æœ‰é™åˆ¶ï¼Œé »ç¹ç™¼é€å¯èƒ½å°è‡´å•é¡Œ

        except Exception as e:
            logging.error(f"Error saving image for user {user_id}: {e}", exc_info=True)
            reply_text = f"åœ–ç‰‡å„²å­˜å¤±æ•—ï¼š{str(e)}" if current_lang == "zh" else f"Failed to save image: {str(e)}"
            line_bot_api.push_message(user_id, TextSendMessage(text=reply_text))

# === è™•ç† Postback äº‹ä»¶ ===
@handler.add(PostbackEvent)
def handle_postback(event):
    global user_saved_lora_models # ç¢ºä¿èƒ½ä¿®æ”¹å…¨åŸŸè®Šæ•¸
    user_id = event.source.user_id
    data = event.postback.data
    logging.info(f"User {user_id} postback data: {data}")

    if user_id not in user_states:
        user_states[user_id] = {'mode': 'main_menu', 'lang': 'zh', 'prompt': None, 'selected_sd_model': None, 'lora_to_name_path': None} # ç¢ºä¿ç‹€æ…‹å­˜åœ¨
    current_state = user_states[user_id]
    current_lang = current_state['lang']

    # --- è™•ç† Stable Diffusion æ¨¡å‹é¸æ“‡é‚è¼¯ (é€™éƒ¨åˆ†æ˜¯ã€Œç”Ÿåœ–åŠŸèƒ½ã€çš„åŸæœ‰é‚è¼¯ï¼Œä¿æŒä¸è®Š) ---
    if data.startswith("action=select_sd_model&model_name="):
        model_name = data.split("model_name=", 1)[1] # å–å¾—æ¨¡å‹æª”æ¡ˆåç¨±
        prompt = current_state.get('prompt') # å¾ç‹€æ…‹ä¸­ç²å–æç¤ºè©

        if not prompt:
            reply_text = "è«‹å…ˆè¼¸å…¥æç¤ºè©ã€‚" if current_lang == "zh" else "Please enter prompt first."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            return

        # å„²å­˜ç”¨æˆ¶é¸æ“‡çš„ SD ä¸»æ¨¡å‹
        current_state['selected_sd_model'] = model_name

        reply_text = "æ­£åœ¨ç”Ÿæˆåœ–ç‰‡ä¸­ï¼Œè«‹ç¨å€™..." if current_lang == "zh" else "Generating image, please wait..."
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} selected SD model: {model_name}, prompt: '{prompt}'")

        # åœ¨æ–°çš„ç·šç¨‹ä¸­åŸ·è¡Œç”Ÿåœ–ï¼Œä¸å¸¶ LoRA æ¨¡å‹
        threading.Thread(target=run_sd_generation, args=(user_id, prompt, model_name, None, event.reply_token)).start() # æ³¨æ„é€™è£¡ lora_model_path å‚³ None
        current_state['prompt'] = None # æ¸…é™¤æç¤ºè©ï¼Œæº–å‚™ä¸‹ä¸€æ¬¡ç”Ÿåœ–
        current_state['selected_sd_model'] = None # æ¸…é™¤å·²é¸æ“‡çš„æ¨¡å‹
        current_state['mode'] = 'main_menu' # ç”Ÿåœ–å®Œæˆæˆ–å¤±æ•—å¾Œå›åˆ°ä¸»é¸å–®æ¨¡å¼
        return

    # --- **å·²ä¿®æ­£ç¸®æ’ï¼šè™•ç†æˆ‘çš„æ¨¡å‹é¸æ“‡é‚è¼¯ (é¸å®Œ LoRA å¾Œç›´æ¥ç”Ÿåœ–)** ---
    elif data.startswith("action=select_my_lora&model_path="): # é€™ä¸€è¡Œç¾åœ¨èˆ‡ä¸Šæ–¹çš„ if å°é½Š
        lora_model_path = data.split("model_path=", 1)[1]
    
        # ç›´æ¥ä½¿ç”¨é è¨­çš„ä¸»æ¨¡å‹å’Œæç¤ºè©
        sd_model_name = DEFAULT_SD_MODEL_FOR_LORA_GEN
        prompt_text = DEFAULT_PROMPT_FOR_LORA_GEN
    
        # æª¢æŸ¥é è¨­ä¸»æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
        full_sd_model_path = os.path.join(SD_MODELS_ROOT, sd_model_name)
        if not os.path.exists(full_sd_model_path):
            reply_text = f"âŒ é è¨­ä¸»æ¨¡å‹ '{sd_model_name}' æœªæ‰¾åˆ°ã€‚è«‹è¯ç¹«ç®¡ç†å“¡æª¢æŸ¥è¨­å®šã€‚" if current_lang == "zh" else f"âŒ Default main model '{sd_model_name}' not found. Please check settings or contact administrator."
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
            current_state['mode'] = 'main_menu' # è¿”å›ä¸»é¸å–®
            return
    
        # çµ¦ç”¨æˆ¶ç”Ÿæˆä¸­çš„æç¤º
        reply_text = "æ­£åœ¨ä½¿ç”¨æ‚¨çš„æ¨¡å‹ç”Ÿæˆåœ–ç‰‡ä¸­ï¼Œè«‹ç¨å€™..." if current_lang == "zh" else "Generating image using your model, please wait..."
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} selected LoRA: {lora_model_path}. Generating with default SD model: {sd_model_name} and prompt: '{prompt_text}'")
    
        # åœ¨æ–°çš„ç·šç¨‹ä¸­åŸ·è¡Œç”Ÿåœ–ï¼Œå‚³å…¥é¸æ“‡çš„ LoRA æ¨¡å‹ã€é è¨­çš„ä¸»æ¨¡å‹å’Œæç¤ºè©
        threading.Thread(target=run_sd_generation,
                         args=(user_id, prompt_text, sd_model_name, lora_model_path, event.reply_token)).start()
    
        # é€™è£¡ä¸éœ€è¦æ”¹è®Šç”¨æˆ¶ç‹€æ…‹ï¼Œå› ç‚º run_sd_generation çµæŸå¾Œæœƒè‡ªå‹•é‡ç½®ç‚º main_menu
        return

        flex_message_content = BubbleContainer(
            direction='ltr',
            header=BoxComponent(
                layout='vertical',
                contents=[
                    TextComponent(text="è«‹é¸æ“‡è¦æ­é…çš„ä¸»æ¨¡å‹é¢¨æ ¼", weight='bold', size='xl', align='center')
                ]
            ),
            body=BoxComponent(
                layout='vertical',
                spacing='md',
                contents=model_buttons
            )
        )
        line_bot_api.reply_message(event.reply_token, FlexSendMessage(alt_text="é¸æ“‡ä¸»æ¨¡å‹é¢¨æ ¼", contents=flex_message_content))
        logging.info(f"User {user_id} selected LoRA model: {lora_model_path}, now selecting main SD model.")
        return


    # --- è™•ç†æ˜¯å¦ä¿ç•™æ¨¡å‹çš„é‚è¼¯ ---
    elif data.startswith("action=retain_lora&path="):
        lora_path = data.split("path=", 1)[1]
        current_state['lora_to_name_path'] = lora_path # å„²å­˜å¾…å‘½åçš„æ¨¡å‹è·¯å¾‘
        current_state['mode'] = 'name_lora_model' # é€²å…¥å‘½åæ¨¡å¼

        reply_text = "è«‹è¼¸å…¥æ‚¨è¦ç‚ºé€™å€‹æ¨¡å‹å‘½åçš„åç¨±ï¼š" if current_lang == "zh" else "Please enter a name for this model:"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} chose to retain LoRA: {lora_path}. Awaiting name.")
        return

    elif data == "action=discard_lora":
        reply_text = "æ¨¡å‹å·²ä¸Ÿæ£„ã€‚å¦‚æœæ‚¨æƒ³å†æ¬¡è¨“ç·´ï¼Œè«‹å¾ä¸»é¸å–®é‡æ–°é–‹å§‹ã€‚" if current_lang == "zh" else "Model discarded. If you want to train again, please restart from the main menu."
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_text))
        logging.info(f"User {user_id} chose to discard LoRA.")
        current_state['mode'] = 'main_menu' # è¿”å›ä¸»é¸å–®
        current_state['lora_to_name_path'] = None # æ¸…é™¤å¾…å‘½åæ¨¡å‹
        return

    logging.warning(f"Unhandled postback event from user {user_id}: {data}")

# --- åœ–ç‰‡è¨“ç·´å®Œæ•´æµç¨‹ ---
# ... (run_full_pipeline å‡½æ•¸é–‹é ­ä¿æŒä¸è®Š)

def run_full_pipeline(user_id):
    global uploading, user_saved_lora_models # ç¢ºä¿èƒ½ä¿®æ”¹å…¨åŸŸè®Šæ•¸
    drive_service_pipeline = authenticate_google_drive()
    if not drive_service_pipeline:
        line_bot_api.push_message(user_id, TextSendMessage(text="âŒ ç„¡æ³•é€£æ¥åˆ° Google Drive æœå‹™ï¼Œè«‹æª¢æŸ¥æœå‹™å¸³æˆ¶é‡‘é‘°ã€‚" if user_states.get(user_id, {}).get('lang', 'zh') == "zh" else "âŒ Could not connect to Google Drive service. Please check service account key."))
        return

    current_lang = user_states.get(user_id, {}).get('lang', 'zh')

    final_lora_path = None # åˆå§‹åŒ–ç‚º None

    try:
        line_bot_api.push_message(user_id, TextSendMessage(text="åœ–ç‰‡ä¸Šå‚³å®Œæˆï¼Œé–‹å§‹æ¨™è¨»å•¦!" if current_lang == "zh" else "Image upload complete, starting tagging!"))
        logging.info(f"User {user_id} started tagging process.")

        # === Step 1: åŸ·è¡Œæ¨™è¨»è…³æœ¬ ===
        print(f"[{user_id}] ğŸš€ é–‹å§‹åŸ·è¡Œæ¨™è¨»è…³æœ¬...")
        # ... (æ¨™è¨»è…³æœ¬åŸ·è¡Œé‚è¼¯ä¸è®Š)
        tag_result = subprocess.run(
            [
                TAGGER_PYTHON,
                TAGGING_SCRIPT,
                UPLOAD_FOLDER,
                "--character_name", "chien",
                "--trigger_word", "masterpiece"
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=TRAIN_SCRIPT_DIR
        )
        logging.info(f"Tagger stdout for user {user_id}:\n{tag_result.stdout}")
        logging.error(f"Tagger stderr for user {user_id}:\n{tag_result.stderr}")
        line_bot_api.push_message(user_id, TextSendMessage(text="æ¨™è¨»å®Œæˆï¼ŒåŸ·è¡Œæ¨¡å‹è¨“ç·´ï¼Œéœ€è¦å¤§æ¦‚10-15åˆ†é˜ã€‚" if current_lang == "zh" else "Tagging complete, starting model training, this will take about 10-15 minutes."))

        # === Step 2: æ¨™è¨»æˆåŠŸå¾ŒåŸ·è¡Œè¨“ç·´ ===
        print(f"[{user_id}] ğŸš€ é–‹å§‹åŸ·è¡Œæ¨¡å‹è¨“ç·´è…³æœ¬...")
        # ... (è¨“ç·´è…³æœ¬åŸ·è¡Œé‚è¼¯ä¸è®Š)
        train_result = subprocess.run(
            ['bash', TRAIN_SCRIPT],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            cwd=TRAIN_SCRIPT_DIR,
            timeout=3000
        )
        logging.info(f"Train stdout for user {user_id}:\n{train_result.stdout}")
        logging.error(f"Train stderr for user {user_id}:\n{train_result.stderr}")
        line_bot_api.push_message(user_id, TextSendMessage(text="æ¨¡å‹è¨“ç·´å·²æˆåŠŸå®Œæˆï¼ğŸ‰ é–‹å§‹ç”Ÿæˆé è¦½åœ–ç‰‡..." if current_lang == "zh" else "Model training completed successfully! ğŸ‰ Starting to generate preview images..."))

        # --- é‡è¦ï¼šç²å–è¨“ç·´å¥½çš„ LoRA æ¨¡å‹è·¯å¾‘ ---
        # æ‚¨éœ€è¦æ ¹æ“šæ‚¨çš„è¨“ç·´è…³æœ¬ (train-t1-Copy2.sh) çš„å¯¦éš›è¼¸å‡ºè·¯å¾‘ä¾†èª¿æ•´é€™è£¡
        # å‡è¨­è¨“ç·´è…³æœ¬æœƒåœ¨ TRAIN_SCRIPT_DIR/output_lora/ ä¸‹ç”Ÿæˆä¸€å€‹åç‚º last_epoch.safetensors çš„æª”æ¡ˆ
        # æˆ–è€…æ‚¨éœ€è¦ä¿®æ”¹ train-t1-Copy2.sh è®“å®ƒè¼¸å‡ºåˆ°ä¸€å€‹å›ºå®šä¸”å¯é æ¸¬çš„æª”æ¡ˆå
        # ä¾‹å¦‚ï¼š
        trained_lora_filename = "last_epoch.safetensors" # å‡è¨­é€™æ˜¯è¨“ç·´è…³æœ¬æœƒè¼¸å‡ºçš„ LoRA æ¨¡å‹åç¨±
        potential_lora_path = os.path.join("/home/user/lora-train/lora-scripts/stable-diffusion-webui/models/Lora/Downloaded_Models/")
        # å¦‚æœæ‚¨çš„è¨“ç·´è…³æœ¬è¼¸å‡ºåˆ°å…¶ä»–åœ°æ–¹ï¼Œè«‹ä¿®æ”¹ potential_lora_path

        if os.path.exists(potential_lora_path):
            final_lora_path = potential_lora_path
            logging.info(f"Found trained LoRA model at: {final_lora_path}")
        else:
            logging.warning(f"Could not find trained LoRA model at expected path: {potential_lora_path}")
            line_bot_api.push_message(user_id, TextSendMessage(text="âš ï¸ è¨“ç·´å®Œæˆï¼Œä½†æ‰¾ä¸åˆ°ç”Ÿæˆçš„ LoRA æ¨¡å‹æª”æ¡ˆã€‚ç„¡æ³•æä¾›ä¿å­˜é¸é …ã€‚" if current_lang == "zh" else "âš ï¸ Training complete, but could not find the generated LoRA model file. Cannot offer save option."))
            final_lora_path = None # ç¢ºä¿å¦‚æœæ‰¾ä¸åˆ°æ¨¡å‹ï¼Œå°±ä¸æœƒé€²å…¥ä¿å­˜æµç¨‹

        # === Step 3: è¨“ç·´æˆåŠŸå¾Œï¼ŒåŸ·è¡Œç”Ÿåœ–è…³æœ¬ chien-generate_random_seeds.py ===
        print(f"[{user_id}] ğŸš€ é–‹å§‹åŸ·è¡Œç”Ÿåœ–è…³æœ¬...")
        # ... (ç”Ÿåœ–è…³æœ¬åŸ·è¡Œé‚è¼¯ä¸è®Š)
        if os.path.exists(GENERATED_IMAGES_OUTPUT_FOLDER):
            shutil.rmtree(GENERATED_IMAGES_OUTPUT_FOLDER)
        os.makedirs(GENERATED_IMAGES_OUTPUT_FOLDER)

        # åœ¨ç”Ÿåœ–è…³æœ¬ä¸­æ‡‰ç”¨å‰›è¨“ç·´å¥½çš„ LoRA æ¨¡å‹
        # é€™å‡è¨­ chien-generate_random_seeds.py æ”¯æ´å¾åƒæ•¸æ¥æ”¶ LoRA è·¯å¾‘ï¼Œ
        # å¦‚æœä¸æ”¯æ´ï¼Œæ‚¨å¯èƒ½éœ€è¦ä¿®æ”¹ chien-generate_random_seeds.py æˆ– SD_API èª¿ç”¨ä¾†å¯¦ç¾
        # é€™è£¡æˆ‘å€‘å‡è¨­å®ƒæœƒè‡ªå‹•æ‰¾åˆ°æœ€æ–°è¨“ç·´çš„æ¨¡å‹ï¼Œæˆ–è€…æ‚¨éœ€è¦å°‡å…¶ä½œç‚ºåƒæ•¸å‚³å…¥
        # ç°¡åŒ–èµ·è¦‹ï¼Œé€™è£¡ä¸ä¿®æ”¹ chien-generate_random_seeds.py çš„èª¿ç”¨ï¼Œè€Œæ˜¯å‡è¨­å®ƒæœƒè‡ªå‹•ä½¿ç”¨æœ€æ–°æ¨¡å‹
        # æˆ–è€…ï¼Œå¦‚æœæ‚¨çš„ chien-generate_random_seeds.py æ˜¯åŸºæ–¼ webuiapi çš„ï¼Œæ‚¨å¯ä»¥é€™æ¨£åšï¼š
        # SD_API.set_loras([{"name": final_lora_path, "weight": 1.0}]) # é€™éœ€è¦ webuiapi çš„æ”¯æ´
        # è€ƒæ…®åˆ°ç›®å‰çš„ GENERATE_SCRIPT æ˜¯å¦ä¸€å€‹ python è…³æœ¬ï¼Œé€™è£¡çš„è™•ç†æ–¹å¼éœ€è¦èˆ‡è©²è…³æœ¬çš„å¯¦éš›è¡Œç‚ºåŒ¹é…ã€‚
        # å¦‚æœæ‚¨çš„ chien-generate_random_seeds.py æœƒè‡ªå‹•åµæ¸¬åˆ° `TRAIN_SCRIPT_DIR/output_lora/` ä¸‹æœ€æ–°çš„ LoRAï¼Œ
        # é‚£é€™è£¡çš„èª¿ç”¨å°±ä¸éœ€è¦é¡å¤–ä¿®æ”¹ã€‚
        # å¦å‰‡ï¼Œæ‚¨å¯èƒ½éœ€è¦å°‡ `final_lora_path` ä½œç‚ºåƒæ•¸å‚³éçµ¦ `GENERATE_SCRIPT`ã€‚
        # å‡è¨­ `chien-generate_random_seeds.py` æ”¯æ´ `--lora_path` åƒæ•¸
        generate_command = ['python3', GENERATE_SCRIPT]
        if final_lora_path:
            generate_command.extend(['--lora_path', final_lora_path]) # å¦‚æœè…³æœ¬æ”¯æ´ï¼Œå‰‡å‚³å…¥ LoRA è·¯å¾‘

        generate_result = subprocess.run(
            generate_command, # ä½¿ç”¨æ›´æ–°å¾Œçš„å‘½ä»¤
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            timeout=300
        )
        logging.info(f"Generate stdout for user {user_id}:\n{generate_result.stdout}")
        logging.error(f"Generate stderr for user {user_id}:\n{generate_result.stderr}")
        line_bot_api.push_message(user_id, TextSendMessage(text="é è¦½åœ–ç‰‡ç”Ÿæˆå®Œæˆ" if current_lang == "zh" else "Preview image generation complete"))

        # === Step 4: å°‡ç”Ÿæˆçš„é è¦½åœ–ç‰‡ä¸Šå‚³åˆ° Google Drive ä¸¦æ¨æ’­çµ¦ä½¿ç”¨è€… ===
        print(f"[{user_id}] ğŸš€ é–‹å§‹ä¸Šå‚³é è¦½åœ–ç‰‡åˆ° Google Drive...")
        image_urls = []
        for filename in os.listdir(GENERATED_IMAGES_OUTPUT_FOLDER):
            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
                img_path = os.path.join(GENERATED_IMAGES_OUTPUT_FOLDER, filename)
                public_link = upload_to_drive_and_get_public_link(
                    drive_service_pipeline, img_path, GOOGLE_DRIVE_GENERATED_IMAGES_FOLDER_ID
                )
                if public_link:
                    image_urls.append(public_link)

        if len(image_urls) == 0:
            line_bot_api.push_message(user_id, TextSendMessage(text="âš ï¸ æœªèƒ½ä¸Šå‚³ä»»ä½•é è¦½åœ–ç‰‡åˆ° Google Driveï¼Œè«‹æª¢æŸ¥è¨­å®šæˆ–ç”Ÿåœ–çµæœã€‚" if current_lang == "zh" else "âš ï¸ No preview images uploaded to Google Drive. Check settings or generation results."))
        else:
            for url in image_urls:
                try:
                    line_bot_api.push_message(user_id, ImageSendMessage(
                        original_content_url=url,
                        preview_image_url=url
                    ))
                except Exception as send_e:
                    logging.error(f"âŒ ç„¡æ³•å‚³é€åœ–ç‰‡è¨Šæ¯ (LINE) for user {user_id}: {send_e}", exc_info=True)
            line_bot_api.push_message(user_id, TextSendMessage(text="ä»¥ä¸‹æ˜¯ä½¿ç”¨æ‚¨è¨“ç·´çš„æ¨¡å‹ç”Ÿæˆçš„é è¦½åœ–ç‰‡ã€‚" if current_lang == "zh" else "Here are preview images generated using your trained model."))

        # === æ–°å¢ Step 5: è©¢å•ä½¿ç”¨è€…æ˜¯å¦ä¿ç•™æ¨¡å‹ ===
        if final_lora_path: # åªæœ‰ç•¶æˆåŠŸæ‰¾åˆ°è¨“ç·´å¥½çš„æ¨¡å‹æ™‚æ‰è©¢å•
            flex_message_content = BubbleContainer(
                direction='ltr',
                header=BoxComponent(
                    layout='vertical',
                    contents=[
                        TextComponent(text="æ¨¡å‹è¨“ç·´å·²å®Œæˆï¼", weight='bold', size='xl', align='center'),
                        TextComponent(text="æ‚¨æƒ³ä¿ç•™é€™å€‹æ¨¡å‹å—ï¼Ÿ", size='md', align='center')
                    ]
                ),
                body=BoxComponent(
                    layout='vertical',
                    spacing='md',
                    contents=[
                        ButtonComponent(
                            style='primary',
                            color='#28A745', # ç¶ è‰²
                            action=PostbackAction(label="ä¿ç•™ä¸¦å‘½å", data=f"action=retain_lora&path={final_lora_path}")
                        ),
                        ButtonComponent(
                            style='secondary',
                            color='#DC3545', # ç´…è‰²
                            action=PostbackAction(label="ä¸ä¿ç•™", data="action=discard_lora")
                        )
                    ]
                )
            )
            line_bot_api.push_message(user_id, FlexSendMessage(alt_text="æ˜¯å¦ä¿ç•™æ¨¡å‹", contents=flex_message_content))
            # æ³¨æ„ï¼šé€™è£¡ä¸ç›´æ¥é‡ç½® mode ç‚º main_menuï¼Œè€Œæ˜¯è®“ç”¨æˆ¶åœ¨å¾ŒçºŒ Postback ä¸­é¸æ“‡
        else:
            line_bot_api.push_message(user_id, TextSendMessage(text="æ¨¡å‹è¨“ç·´æµç¨‹å·²çµæŸã€‚è«‹è¼¸å…¥ 'menu' å›åˆ°ä¸»é¸å–®ã€‚" if current_lang == "zh" else "Model training process has ended. Please type 'menu' to return to the main menu."))
            # å¦‚æœæ²’æœ‰æ¨¡å‹å¯ä¿å­˜ï¼Œç›´æ¥å›ä¸»é¸å–®æ¨¡å¼
            user_states[user_id]['mode'] = 'main_menu'


    except subprocess.CalledProcessError as e:
        error_message = f"ç¨‹å¼åŸ·è¡Œå¤±æ•—: {e.cmd}\néŒ¯èª¤è¼¸å‡º:\n{e.stderr}" if current_lang == "zh" else f"Program failed: {e.cmd}\nError output:\n{e.stderr}"
        logging.error(f"å­ç¨‹åºéŒ¯èª¤ for user {user_id}: {error_message}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼Œè«‹è¯çµ¡ç®¡ç†å“¡ã€‚\néŒ¯èª¤è©³æƒ…ï¼š{error_message}" if current_lang == "zh" else f"âŒ An error occurred during processing. Please contact the administrator.\nError details: {error_message}"))
        user_states[user_id]['mode'] = 'main_menu' # éŒ¯èª¤æ™‚ä¹Ÿå›åˆ°ä¸»é¸å–®
    except FileNotFoundError as e:
        error_message = f"æ‰¾ä¸åˆ°æª”æ¡ˆæˆ–ç¨‹å¼: {e}" if current_lang == "zh" else f"File or program not found: {e}"
        logging.error(f"æª”æ¡ˆæœªæ‰¾åˆ°éŒ¯èª¤ for user {user_id}: {error_message}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"âŒ å¿…è¦çš„æª”æ¡ˆæˆ–ç¨‹å¼ï¼ˆå¦‚ Python è§£é‡‹å™¨ã€è…³æœ¬ï¼‰æœªæ‰¾åˆ°ã€‚è«‹è¯çµ¡ç®¡ç†å“¡ã€‚\néŒ¯èª¤è©³æƒ…ï¼š{error_message}" if current_lang == "zh" else f"âŒ Required file or program (e.g., Python interpreter, script) not found. Please contact the administrator.\nError details: {error_message}"))
        user_states[user_id]['mode'] = 'main_menu' # éŒ¯èª¤æ™‚ä¹Ÿå›åˆ°ä¸»é¸å–®
    except subprocess.TimeoutExpired as e:
        error_message = f"è™•ç†è¶…æ™‚: {e.cmd}" if current_lang == "zh" else f"Processing timed out: {e.cmd}"
        logging.error(f"è¶…æ™‚éŒ¯èª¤ for user {user_id}: {error_message}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"âŒ è™•ç†è¶…æ™‚ã€‚é€™å¯èƒ½è¡¨ç¤ºè¨“ç·´æˆ–ç”Ÿåœ–éç¨‹å¤ªé•·ã€‚è«‹è¯çµ¡ç®¡ç†å“¡ã€‚\néŒ¯èª¤è©³æƒ…ï¼š{error_message}" if current_lang == "zh" else f"âŒ Processing timed out. This may indicate the training or generation process is too long. Please contact the administrator.\nError details: {error_message}"))
        user_states[user_id]['mode'] = 'main_menu' # éŒ¯èª¤æ™‚ä¹Ÿå›åˆ°ä¸»é¸å–®
    except Exception as e:
        logging.error(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ for user {user_id}: {e}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"âŒ ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ã€‚è«‹è¯çµ¡ç®¡ç†å“¡ã€‚\néŒ¯èª¤è©³æƒ…ï¼š{e}" if current_lang == "zh" else f"âŒ An unknown error occurred. Please contact the administrator.\nError details: {e}"))
        user_states[user_id]['mode'] = 'main_menu' # éŒ¯èª¤æ™‚ä¹Ÿå›åˆ°ä¸»é¸å–®
    finally:
        # ç„¡è«–æˆåŠŸå¤±æ•—ï¼Œä¸”ç”¨æˆ¶æœªé¸æ“‡ä¿ç•™æ¨¡å‹ï¼Œéƒ½æœƒæ¸…ç†ç‹€æ…‹å’Œä¸Šå‚³è³‡æ–™å¤¾
        # å¦‚æœç”¨æˆ¶é¸æ“‡äº†ä¿ç•™æ¨¡å‹ï¼Œç‹€æ…‹æœƒè¢«åˆ‡æ›åˆ° 'name_lora_model'ï¼Œç­‰å¾…ç”¨æˆ¶å‘½å
        # åœ¨ 'name_lora_model' æ¨¡å¼ä¸‹ï¼Œä¸æ‡‰ç«‹å³æ¸…ç†æ¨¡å‹æª”æ¡ˆ
        if user_states[user_id]['mode'] != 'name_lora_model':
            user_states[user_id]['mode'] = 'main_menu'
            user_states[user_id]['image_count'] = 0
            user_id_for_process = None # æ¸…é™¤è§¸ç™¼ç”¨æˆ¶ID
            uploading = False # é‡ç½®ä¸Šå‚³ç‹€æ…‹
            user_states[user_id]['lora_to_name_path'] = None # æ¸…é™¤å¾…å‘½åæ¨¡å‹è·¯å¾‘

            if os.path.exists(UPLOAD_FOLDER):
                try:
                    shutil.rmtree(UPLOAD_FOLDER)
                    logging.info(f"Cleaned up UPLOAD_FOLDER for user {user_id}.")
                except OSError as e:
                    logging.error(f"Error cleaning up UPLOAD_FOLDER after pipeline: {e}")

        # å¦‚æœç”Ÿæˆäº† LoRA æ¨¡å‹ï¼Œä¸¦ä¸”ç”¨æˆ¶é¸æ“‡ä¿ç•™ï¼Œé€™è£¡éœ€è¦åŸ·è¡Œæ¨¡å‹ç§»å‹•
        if final_lora_path and user_states[user_id].get('lora_to_name_path') == final_lora_path:
            lora_basename = os.path.basename(final_lora_path)
            destination_path = os.path.join(LORA_DOWNLOADED_MODELS_FOLDER, lora_basename)
            try:
                shutil.move(final_lora_path, destination_path)
                user_states[user_id]['lora_to_name_path'] = destination_path # æ›´æ–°ç‹€æ…‹ä¸­çš„è·¯å¾‘ç‚ºæœ€çµ‚å„²å­˜è·¯å¾‘
                logging.info(f"Moved LoRA model from {final_lora_path} to {destination_path}")
            except Exception as e:
                logging.error(f"Error moving LoRA model {final_lora_path} to {destination_path}: {e}")
                line_bot_api.push_message(user_id, TextSendMessage(text="âš ï¸ æ¨¡å‹ä¿å­˜å¤±æ•—ï¼è«‹è¯ç¹«ç®¡ç†å“¡ã€‚" if current_lang == "zh" else "âš ï¸ Model save failed! Please contact the administrator."))
# --- ç¨ç«‹çš„ç”Ÿåœ–æµç¨‹ (ä½¿ç”¨ webuiapi) ---
# æ–°å¢ä¸€å€‹åƒæ•¸ lora_model_pathï¼Œé è¨­ç‚º None
def run_sd_generation(user_id, prompt, sd_model_name, lora_model_path=None, reply_token=None):
    drive_service_sd = authenticate_google_drive()
    if not drive_service_sd:
        line_bot_api.push_message(user_id, TextSendMessage(text="âŒ ç„¡æ³•é€£æ¥åˆ° Google Drive æœå‹™ï¼Œè«‹æª¢æŸ¥æœå‹™å¸³æˆ¶é‡‘é‘°ã€‚" if user_states.get(user_id, {}).get('lang', 'zh') == "zh" else "âŒ Could not connect to Google Drive service. Please check service account key."))
        return

    current_lang = user_states.get(user_id, {}).get('lang', 'zh')

    try:
        # è¨­å®šä¸»æ¨¡å‹
        logging.info(f"Attempting to set SD main model: {sd_model_name}")
        SD_API.util_set_model(sd_model_name)
        logging.info(f"SD API main model set to: {sd_model_name}")

        # ç¿»è­¯æç¤ºè© (å¦‚æœéœ€è¦)
        translated_prompt = prompt
        if current_lang == "zh":
            try:
                translated_prompt = GoogleTranslator(source='zh-TW', target='en').translate(prompt)
                logging.info(f"Translated prompt from '{prompt}' to '{translated_prompt}'")
            except Exception as e:
                logging.warning(f"Prompt translation failed: {e}. Using original prompt.")
                translated_prompt = prompt

        # æ§‹å»º LoRA åƒæ•¸
        lora_components = []
        if lora_model_path:
            # webuiapi çš„ set_loras æœŸæœ› LoRA æª”æ¡ˆåç¨±ï¼Œè€Œä¸æ˜¯å®Œæ•´è·¯å¾‘
            # æ‰€ä»¥é€™è£¡éœ€è¦å¾å®Œæ•´è·¯å¾‘ä¸­æå–æª”æ¡ˆåç¨±
            lora_filename = os.path.basename(lora_model_path)
            lora_components.append({"name": lora_filename, "weight": 1.0}) # å‡è¨­æ¬Šé‡ç‚º 1.0

            logging.info(f"Applying LoRA model: {lora_filename} with weight 1.0")
            # æ³¨æ„ï¼šé€™è£¡ç›´æ¥ä¿®æ”¹ SD_API çš„å…§éƒ¨è¨­å®šï¼Œå¯èƒ½æœƒå½±éŸ¿å…¶ä»–åŒæ™‚ç”Ÿæˆçš„ä»»å‹™
            # æ›´å¥½çš„åšæ³•æ˜¯åœ¨ txt2img åƒæ•¸ä¸­å‚³é LoRA
            # SD_API.set_loras(lora_components) # é€™æ˜¯ webuiapi çš„ä¸€å€‹æ–¹æ³•ï¼Œä½†å¯èƒ½ä¸å¦‚ override_settings ç©©å®š

        # ç”Ÿæˆåœ–ç‰‡
        logging.info(f"Calling SD API for generation with prompt: '{translated_prompt}', main model: {sd_model_name}, LoRA: {lora_model_path}")

        temp_output_dir = "output"
        os.makedirs(temp_output_dir, exist_ok=True)

        # ä½¿ç”¨ override_settings ä¾†æŒ‡å®š LoRA æ¨¡å‹ï¼Œé€™æ˜¯æ›´ç©©å®šçš„åšæ³•
        # LoRA çš„åç¨±åœ¨ override_settings ä¸­æ‡‰æ˜¯ webui ä¸­ LoRA çš„çŸ­åç¨±æˆ–æª”æ¡ˆå (ä¸å«è·¯å¾‘)
        # ä¾‹å¦‚ï¼š<lora:lora_name:weight>
        # é€™è£¡å‡è¨­ LORA_DOWNLOADED_MODELS_FOLDER è£¡çš„ LoRA æœƒè¢« SD WebUI è‡ªå‹•è¼‰å…¥ä¸¦å¯ç”¨åç¨±
        lora_string = ""
        if lora_model_path:
            # å¾å®Œæ•´è·¯å¾‘ä¸­æå–ä¸å«å‰¯æª”åçš„æª”æ¡ˆåç¨±ä½œç‚º LoRA çš„çŸ­åç¨±
            lora_name_for_prompt = os.path.splitext(os.path.basename(lora_model_path))[0]
            lora_string = f" <lora:{lora_name_for_prompt}:1.0>" # æ·»åŠ åˆ°æç¤ºè©ä¸­

        result = SD_API.txt2img(
            prompt=translated_prompt + lora_string, # å°‡ LoRA èªæ³•åŠ å…¥æç¤ºè©
            negative_prompt="bad anatomy, low quality, deformed, worst quality, missing fingers, extra fingers, blurry",
            seed=-1,
            steps=30,
            cfg_scale=7,
            width=512,
            height=768,
            save_images=True,
            override_settings={"sd_model_checkpoint": sd_model_name} # ç¢ºä¿ä½¿ç”¨æŒ‡å®šä¸»æ¨¡å‹
        )

        if result and result.images:
            generated_image_path = os.path.join(temp_output_dir, "generated_image.png")
            result.images[0].save(generated_image_path)
            logging.info(f"Generated image saved to: {generated_image_path}")

            public_url = upload_to_drive_and_get_public_link(
                drive_service_sd, generated_image_path, GOOGLE_DRIVE_SD_OUTPUT_FOLDER_ID
            )

            if public_url:
                try:
                    line_bot_api.push_message(user_id, ImageSendMessage(
                        original_content_url=public_url,
                        preview_image_url=public_url
                    ))
                    line_bot_api.push_message(user_id, TextSendMessage(text="æ‚¨çš„åœ–ç‰‡å·²ç”Ÿæˆï¼" if current_lang == "zh" else "Your image has been generated!"))
                except Exception as send_e:
                    logging.error(f"âŒ ç„¡æ³•å‚³é€åœ–ç‰‡è¨Šæ¯ (LINE) for user {user_id}: {send_e}", exc_info=True)
                    line_bot_api.push_message(user_id, TextSendMessage(text="åœ–ç‰‡ç”ŸæˆæˆåŠŸï¼Œä½†ç„¡æ³•ç™¼é€çµ¦æ‚¨ã€‚è«‹è¯ç¹«ç®¡ç†å“¡ã€‚" if current_lang == "zh" else "Image generated successfully, but could not be sent to you. Please contact the administrator."))
            else:
                line_bot_api.push_message(user_id, TextSendMessage(text="åœ–ç‰‡ç”ŸæˆæˆåŠŸï¼Œä½†ä¸Šå‚³è‡³ Google Drive å¤±æ•—ã€‚è«‹è¯ç¹«ç®¡ç†å“¡ã€‚" if current_lang == "zh" else "Image generated successfully, but failed to upload to Google Drive. Please contact the administrator."))
        else:
            line_bot_api.push_message(user_id, TextSendMessage(text="åœ–ç‰‡ç”Ÿæˆå¤±æ•—ï¼Œè«‹æª¢æŸ¥æç¤ºè©æˆ–è¨­å®šã€‚" if current_lang == "zh" else "Image generation failed. Please check your prompt or settings."))
            logging.error(f"SD API did not return images for user {user_id} with prompt: '{prompt}'")

    except Exception as e:
        logging.error(f"SD Generation error for user {user_id}: {e}", exc_info=True)
        line_bot_api.push_message(user_id, TextSendMessage(text=f"åœ–ç‰‡ç”Ÿæˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}ã€‚è«‹ç¨å¾Œå†è©¦ã€‚" if current_lang == "zh" else f"An error occurred during image generation: {str(e)}. Please try again later."))
    finally:
        if os.path.exists(temp_output_dir) and os.path.isdir(temp_output_dir):
            try:
                shutil.rmtree(temp_output_dir)
                logging.info(f"Cleaned up temporary output directory: {temp_output_dir}")
            except OSError as e:
                logging.error(f"Error cleaning up temporary output directory: {e}")
# ... (å…¶ä»– import)

if __name__ == "__main__":
    os.makedirs(MODEL_FOLDER, exist_ok=True)
    if not os.path.exists(UPLOAD_FOLDER):
        os.makedirs(UPLOAD_FOLDER)
    if not os.path.exists(GENERATED_IMAGES_OUTPUT_FOLDER):
        os.makedirs(GENERATED_IMAGES_OUTPUT_FOLDER)
    if not os.path.exists("output"):
        os.makedirs("output")
    # ç¢ºä¿æ–°çš„ LoRA æ¨¡å‹å„²å­˜è³‡æ–™å¤¾å­˜åœ¨
    os.makedirs(LORA_DOWNLOADED_MODELS_FOLDER, exist_ok=True) # æ–°å¢

    print(f"å·²å‰µå»ºæ¨¡å‹ç›®éŒ„ï¼š{MODEL_FOLDER}ï¼Œè«‹å°‡ .safetensors æ¨¡å‹æ–‡ä»¶æ”¾å…¥æ­¤ç›®éŒ„ã€‚")
    print(f"å·²å‰µå»º LoRA æ¨¡å‹ä¸‹è¼‰ç›®éŒ„ï¼š{LORA_DOWNLOADED_MODELS_FOLDER}ï¼Œè¨“ç·´å®Œæˆçš„ LoRA å°‡ä¿å­˜æ–¼æ­¤ã€‚")

    # ç‚ºäº†æ–¹ä¾¿æ¸¬è©¦ï¼Œæ‚¨å¯ä»¥å‰µå»ºä¸€äº›å‡çš„æ¨¡å‹æ–‡ä»¶ï¼Œå¦‚æœå®ƒå€‘ä¸å­˜åœ¨çš„è©±
    for model_name in MODEL_STYLES.keys():
        dummy_model_path = os.path.join(MODEL_FOLDER, model_name)
        if not os.path.exists(dummy_model_path):
            with open(dummy_model_path, 'w') as f:
                f.write(f"This is a dummy file for {model_name}")
            print(f"å·²å‰µå»ºå‡æ¨¡å‹æ–‡ä»¶ï¼š{dummy_model_path}")


    dummy_lora_path = os.path.join(LORA_DOWNLOADED_MODELS_FOLDER, "dummy_lora_test.safetensors")
    if not os.path.exists(dummy_lora_path):
        with open(dummy_lora_path, 'w') as f:
            f.write(f"This is a dummy LoRA model for testing.")

        print(f"å·²å‰µå»ºå‡ LoRA æ¨¡å‹æ–‡ä»¶ï¼š{dummy_lora_path}")


    port = int(os.environ.get('PORT', 8000))
    app.run(host='0.0.0.0', port=port)